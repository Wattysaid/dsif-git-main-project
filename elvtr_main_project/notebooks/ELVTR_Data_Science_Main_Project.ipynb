{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELVTR Data Science Main Project\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "### 01 Git Repository\n",
    "\n",
    "Include all project code with a README file containing a high-level project description.\n",
    "\n",
    "Example README guide: [Make a README](link-to-readme-guide)\n",
    "\n",
    "### 02 Report\n",
    "\n",
    "* Methodology, approach, and model selection rationale.\n",
    "* Advantages and limitations of the chosen model.\n",
    "* Architecture of the final solution.\n",
    "* Considerations on deployment and scalability of the solution - i.e., how will the model be used in BAU by the business?\n",
    "* Estimated impact/ROI of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science in Finance: Lending Club Loan Analysis\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "Lending Club has tasked us with preparing a loan application dataset for analysis and predictive modeling. \n",
    "\n",
    "The key tasks include data cleaning, exploratory data analysis, and building a predictive model for loan classification. An optional component involves building a real-time scoring application.\n",
    "\n",
    "**Project Objectives**:\n",
    "- Clean and preprocess the data.\n",
    "- Perform exploratory data analysis (EDA) to gain insights.\n",
    "- Develop a predictive model for loan application approval.\n",
    "- (Optional) Build a real-time scoring application.\n",
    "\n",
    "**Dataset Description**:\n",
    "The dataset consists of loan application records, including various financial metrics and the application status. The data dictionary is provided for understanding the attributes.\n",
    "\n",
    "**Dataset Path**:\n",
    "- CSV: `data/1-raw/lending-club-2007-2020Q3/Loan_status_2007-2020Q3-100ksample.csv`\n",
    "- Data Dictionary: `data/1-raw/lending-club-2007-2020Q3/LCDataDictionary.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options for pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data xlsx file as a dataframe\n",
    "df = pd.read_csv(\"c:\\\\Users\\\\kiera\\\\OneDrive\\\\Documents\\\\GitHub\\\\dsif-git-main-project\\\\elvtr_main_project\\\\data\\\\raw\\\\Loan_status_2007-2020Q3\\\\Loan_status_2007-2020Q3-100k-Full-Data.csv\")\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data dictionary CSV file as a dataframe\n",
    "df_data_dict = pd.read_excel(\"c:\\\\Users\\\\kiera\\\\OneDrive\\\\Documents\\\\GitHub\\\\dsif-git-main-project\\\\elvtr_main_project\\\\data\\\\raw\\\\Loan_status_2007-2020Q3\\\\LCDataDictionary.xlsx\")\n",
    "\n",
    "df_data_dict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the employtment mapping CSV file as a dataframe\n",
    "df_emp_title = pd.read_csv(\"c:\\\\Users\\\\kiera\\\\OneDrive\\\\Documents\\\\GitHub\\\\dsif-git-main-project\\\\elvtr_main_project\\\\data\\\\raw\\\\emp_title_mapping.csv\")\n",
    "\n",
    "df_emp_title.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Basic Data Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data contains 143 columns and 99999 rows of data. It is comprised of numerical (float, int) and categorical data (object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists for LoanStatNew and Description\n",
    "loanstatnew = []\n",
    "description = []\n",
    "\n",
    "# Iterate through each row in the DataFrame and populate lists\n",
    "for _, row in df.iterrows():\n",
    "    loanstatnew.append(row['LoanStatNew'])\n",
    "    description.append(row['Description'])\n",
    "\n",
    "# Display lists to verify\n",
    "print(\"LoanStatNew list:\", loanstatnew)\n",
    "print(\"Description list:\", description)\n",
    "\n",
    "# Apply simple styling (optional display for Jupyter Notebooks or specific environments)\n",
    "df.style.set_properties(**{'text-align': 'left', 'white-space': 'nowrap'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'LoanStatNew': ['acc_now_delinq', 'acc_open_past_24mths', 'addr_state', 'all_util', 'annual_inc'],\n",
    "    'Description': [\n",
    "        'The number of accounts on which the borrower is now delinquent.',\n",
    "        'Number of trades opened in past 24 months.',\n",
    "        'The state provided by the borrower in the loan application',\n",
    "        'Balance to credit limit on all trades',\n",
    "        'The self-reported annual income provided by the borrower during registration.'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply simple styling\n",
    "df.style.set_properties(**{'text-align': 'left', 'white-space': 'nowrap'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01 Data Preparation and Cleaning\n",
    "\n",
    "Perform thorough data cleaning on the provided dataset, including but not limited to the following steps:\n",
    "\n",
    "* Handling missing values (imputation or removal)\n",
    "* Converting data types to appropriate formats\n",
    "* Removing duplicate records\n",
    "* Detecting and handling outliers\n",
    "* Standardizing and normalizing data\n",
    "* Encoding categorical variables\n",
    "* Cleaning and preprocessing string data\n",
    "* Extracting features from date columns\n",
    "\n",
    "Students are encouraged to perform additional data cleaning steps beyond those implemented in class (e.g., cleaning of additional columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Exploratory Data Analysis\n",
    "\n",
    "Conduct an in-depth analysis of the dataset with a focus on the target variable. The analysis should include:\n",
    "\n",
    "* Exploring the distribution, symmetry, and potential issues with the target variable.\n",
    "* Using visualization techniques (e.g., histograms, box plots, scatter plots) and statistical analysis to explore relationships between the target variable and independent variables.\n",
    "* Identifying important variables with predictive relevance.\n",
    "* Determining which variables or levels can be excluded.\n",
    "* Identifying variables with outliers and applying transformations if necessary.\n",
    "* Handling missing values and explaining the chosen treatment.\n",
    "* Examining interrelationships between independent variables and considering transformations.\n",
    "* Assessing class balance and addressing any imbalance if needed.\n",
    "* Summarizing insights and plans to leverage the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 Modelling\n",
    "\n",
    "Recommend and justify a model to predict class membership of loan applications. The modeling phase should include:\n",
    "\n",
    "* Selecting a baseline model for comparison.\n",
    "* Recommending a challenger model with a detailed justification.\n",
    "* Describing all data preprocessing steps and measurement of accuracy.\n",
    "* Choosing appropriate models and evaluation metrics.\n",
    "* Explaining the choice of models, preprocessing methods, and accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04 Optional - Real-time scoring application\n",
    "\n",
    "Build a \"real-time\" application that can score new loan application observations. The implementation details are at the consultant's discretion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
