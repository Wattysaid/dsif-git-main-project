{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline - Clean Code Version\n",
    "\n",
    "This notebook demonstrates a comprehensive machine learning pipeline, including data preprocessing, feature engineering, model training, and evaluation for both binary and multi-class classification tasks. Below is an outline of each key section:\n",
    "\n",
    "1. **Library Imports**: Loads all essential libraries for data handling, visualization, model training, evaluation, and saving.\n",
    "\n",
    "2. **Data Loading and Cleaning**: Reads the dataset, standardizes column names, and applies initial data quality checks for missing and infinite values.\n",
    "\n",
    "3. **Data Preprocessing**:\n",
    "   - Categorical features are filled and encoded using binary encoding.\n",
    "   - Missing values in numerical features are imputed.\n",
    "   - Missing data indicators are created for further analysis.\n",
    "\n",
    "4. **Feature Engineering**:\n",
    "   - Calculates Variance Inflation Factor (VIF) to identify and remove features with high multicollinearity.\n",
    "   - Applies Recursive Feature Elimination (RFE) with Linear Regression and RandomForest for feature selection.\n",
    "\n",
    "5. **Multi-Class Strategy Setup**:\n",
    "   - Defines a function to wrap models in appropriate multi-class strategies (`OneVsOne` or `OneVsRest`) when applicable.\n",
    "\n",
    "6. **Model Evaluation Functions**:\n",
    "   - `evaluate_model_single`: Evaluates binary classification models, displaying ROC and Precision-Recall curves, metrics, and confusion matrix.\n",
    "   - `evaluate_model_multi`: Evaluates multi-class classification models with class-specific ROC and Precision-Recall curves.\n",
    "\n",
    "7. **Column Removal**: Removes specified columns from training and test datasets to ensure only relevant features are included in modeling.\n",
    "\n",
    "8. **Model Training and Evaluation**:\n",
    "   - Iterates over models, evaluating each based on user-defined selection and multi-class strategy, with progress tracked by a progress bar.\n",
    "   - Stores and displays the evaluation metrics, including accuracy, precision, recall, F1-score, ROC-AUC, and cross-validation accuracy.\n",
    "\n",
    "9. **Results Summary and Visualization**:\n",
    "   - Summarizes results in a DataFrame and saves them to a CSV file.\n",
    "   - Plots a comparison of performance metrics across models for quick assessment.\n",
    "\n",
    "10. **Model Saving and Reloading**:\n",
    "    - Saves all trained models to disk for future use.\n",
    "    - Demonstrates reloading saved models and making predictions to validate accuracy.\n",
    "\n",
    "This pipeline is designed to handle both binary and multi-class problems, supports multiple models, and provides detailed performance analysis and visualization for decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let the Fun Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below code Block Explanation**: This block imports essential libraries required for data handling, encoding, visualization, machine learning models, feature selection, and evaluation metrics. Grouping imports helps keep the code organized, and importing them all at once avoids repetitive imports later in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Import Required Libraries ===\n",
    "\n",
    "# Data Manipulation and Preprocessing\n",
    "import pandas as pd         # Core data manipulation library\n",
    "import numpy as np          # Mathematical operations\n",
    "import category_encoders as ce  # Encoding categorical variables\n",
    "\n",
    "# Statistical Analysis\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest, shapiro, anderson, kstest, skew\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor  # For multicollinearity checks (VIF)\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt         # Basic plotting\n",
    "import seaborn as sns                   # Advanced static visualizations with themes\n",
    "import plotly.express as px             # Interactive plots\n",
    "import missingno as msno                # Visualizing missing data\n",
    "\n",
    "# Data Preprocessing and Encoding\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, label_binarize  # Scaling and label encoding\n",
    "from sklearn.model_selection import train_test_split, cross_val_score           # Data splitting and cross-validation\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression           # Linear models for classification and regression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor          # Decision Tree models\n",
    "from sklearn.ensemble import (                                                 \n",
    "    RandomForestClassifier, RandomForestRegressor,                              # Random Forest models\n",
    "    GradientBoostingClassifier, GradientBoostingRegressor                       # Gradient Boosting models\n",
    ")\n",
    "from sklearn.svm import SVC, SVR                                               # Support Vector Machine for classification and regression\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor        # K-Nearest Neighbors for classification and regression\n",
    "from sklearn.naive_bayes import GaussianNB                                     # Naive Bayes for classification\n",
    "from sklearn.cluster import KMeans                                             # KMeans clustering\n",
    "from sklearn.decomposition import PCA                                          # Principal Component Analysis (PCA) for dimensionality reduction\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier         # Multi-class classification strategies\n",
    "\n",
    "# Advanced Machine Learning Models\n",
    "from xgboost import XGBClassifier         # Extreme Gradient Boosting\n",
    "from lightgbm import LGBMClassifier       # Light Gradient Boosting Machine\n",
    "from catboost import CatBoostClassifier   # CatBoost Gradient Boosting\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import RFE  # Recursive Feature Elimination (RFE) for feature selection\n",
    "\n",
    "# Model Evaluation Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,      # Basic classification metrics\n",
    "    roc_auc_score, confusion_matrix,                             # Advanced metrics and confusion matrix\n",
    "    roc_curve, precision_recall_curve, average_precision_score    # Curve metrics for model evaluation\n",
    ")\n",
    "\n",
    "# Deep Learning with TensorFlow/Keras\n",
    "from tensorflow.keras.models import Sequential          # Sequential model setup in Keras\n",
    "from tensorflow.keras.layers import Dense               # Dense layers for neural networks\n",
    "\n",
    "# Utilities\n",
    "from tqdm import tqdm       # Progress bar for loops\n",
    "import joblib               # For saving/loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below code Block Explanation**: This block loads the dataset and standardizes column names by removing extra spaces, converting to lowercase, and replacing spaces with underscores for better accessibility in code. Printing the cleaned headers and the shape of the DataFrame provides a quick verification that the data has loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Clean Data\n",
    "df = pd.read_csv(\"c:\\\\Users\\\\kiera\\\\OneDrive\\\\Documents\\\\GitHub\\\\dsif-git-main-project\\\\elvtr_main_project\\\\data\\\\1-raw\\\\lending-club-2007-2020Q3\\\\Loan_status_2007-2020Q3-100ksample.csv\")\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "print(\"Cleaned headers:\", df.columns.tolist())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below code Block Explanation**: Here, the display options for pandas are set to show all columns and rows, which is useful during data exploration to get a complete view. Additionally, a white grid theme is applied to Seaborn plots, providing a consistent look for visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration and Display Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "sns.set_theme(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below code Block Explanation**: Now let's look at our Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data contains 143 columns and 99999 rows of data. It is comprised of numerical (float, int) and categorical data (object)\n",
    "\n",
    "Our target/Y feature is `loan_status`. Let's look through our feature list and determine which fields are of most value when predicting `loan_status`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below Code Blcok Explanation**: Hereunder we've listed, based on the definitions of the data dictionary, all features that are [pre hardship flags and useful for our analysis.\n",
    "\n",
    "This will form our initial `feature_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [\n",
    "    'acc_now_delinq', 'acc_open_past_24mths', 'addr_state', 'all_util', 'annual_inc', \n",
    "    'annual_inc_joint', 'application_type', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', \n",
    "    'chargeoff_within_12_mths', 'collections_12_mths_ex_med', 'delinq_2yrs', 'delinq_amnt', \n",
    "    'dti', 'dti_joint', 'earliest_cr_line', 'emp_length', 'emp_title', \n",
    "    'fico_range_high', 'fico_range_low', 'funded_amnt', 'funded_amnt_inv', 'grade', \n",
    "    'home_ownership', 'il_util', 'initial_list_status', 'inq_fi', 'inq_last_12m', \n",
    "    'inq_last_6mths', 'installment', 'int_rate', 'issue_d', 'loan_amnt', 'loan_status', \n",
    "    'max_bal_bc', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', \n",
    "    'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc', 'mths_since_last_delinq', \n",
    "    'mths_since_last_major_derog', 'mths_since_last_record', 'mths_since_rcnt_il', \n",
    "    'mths_since_recent_bc', 'mths_since_recent_bc_dlq', 'mths_since_recent_inq', \n",
    "    'mths_since_recent_revol_delinq', 'num_accts_ever_120_pd', 'num_actv_bc_tl', \n",
    "    'num_actv_rev_tl', 'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl', \n",
    "    'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m', 'num_tl_30dpd', \n",
    "    'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', 'open_acc', 'open_acc_6m', 'open_il_12m', \n",
    "    'open_il_24m', 'open_act_il', 'open_rv_12m', 'open_rv_24m', 'out_prncp', \n",
    "    'out_prncp_inv', 'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'policy_code', 'pub_rec', \n",
    "    'pub_rec_bankruptcies', 'purpose', 'pymnt_plan', 'revol_bal', 'revol_util', \n",
    "    'sub_grade', 'tax_liens', 'term', 'title', 'tot_coll_amt', 'tot_cur_bal', \n",
    "    'tot_hi_cred_lim', 'total_acc', 'total_bal_ex_mort', 'total_bal_il', 'total_bc_limit', \n",
    "    'total_cu_tl', 'total_il_high_credit_limit', 'total_pymnt', 'total_pymnt_inv', \n",
    "    'total_rec_int', 'total_rec_late_fee', 'total_rec_prncp', 'total_rev_hi_lim', \n",
    "    'verification_status', 'zip_code'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below Code Block Explanation**: This block filters our data frame (`df`) to the `feature_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Our data frame is complrised of (rows, cols): {df[feature_list].shape}\")\n",
    "df[feature_list].head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below Code Block Explanation**: The below code creates a bar char for us to evaluate our`loan_status` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the value counts for loan status\n",
    "loan_status_counts = df['loan_status'].value_counts()\n",
    "\n",
    "# Plot with matplotlib\n",
    "plt.figure(figsize=(7, 5))  # width=500/100 and height=350/100 for similar sizing in inches\n",
    "loan_status_counts.plot(kind='bar')\n",
    "\n",
    "# Set title and labels\n",
    "plt.title(\"Loan Status Counts\")\n",
    "plt.xlabel(\"Loan Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simplify this list and create a more black and white view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below Code Block Explained**: This block creates a logical grouping for Paid Loans, and Defaulted loans. It then further loops through the data frame and retains only the rows that contain Paid Loans and Defaulted Loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logical groupings for 'loan_status'\n",
    "loan_status_groupings = {\n",
    "    'Fully Paid': 'Paid Loan',\n",
    "    'Does not meet the credit policy. Status:Fully Paid': 'Paid Loan',\n",
    "    'Charged Off': 'Defaulted Loan',\n",
    "    'Does not meet the credit policy. Status:Charged Off': 'Defaulted Loan',\n",
    "    'Default': 'Defaulted Loan'\n",
    "}\n",
    "\n",
    "# Apply the grouping to the 'loan_status' column\n",
    "df['loan_status_grouped_kn'] = df['loan_status'].replace(loan_status_groupings)\n",
    "\n",
    "# Retain only rows with 'Paid Loan' or 'Defaulted Loan'\n",
    "df = df[df['loan_status_grouped_kn'].isin(['Paid Loan', 'Defaulted Loan'])]\n",
    "\n",
    "# Verify the groupings\n",
    "print(df['loan_status_grouped_kn'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Newly created columns\n",
    "new_columns = ['loan_status_grouped_kn']  # Replace with columns name\n",
    "\n",
    "# Add new columns to feature_list if they're not already in the list\n",
    "feature_list.extend([col for col in new_columns if col not in feature_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below Code Block Explanation**: This block visualizes the distribution of loan amounts for each loan status category using Kernel Density Estimation (KDE) plots. It iterates over the unique values of loan_status_grouped_kn and creates a filled KDE plot for each category (Paid Loan or Defaulted Loan). The resulting graph allows for a comparison of loan amount distributions between different loan statuses, providing insights into any potential differences in loan amount trends across the two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "for status in df['loan_status_grouped_kn'].unique():\n",
    "    sns.kdeplot(df[df['loan_status_grouped_kn'] == status]['loan_amnt'], label=status, fill=True)\n",
    "plt.title('Distribution of Loan Amount by Loan Status')\n",
    "plt.xlabel('Loan Amount')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(title=\"Loan Status\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the loan_status against employment length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emp_length'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emp_length'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that `emp_length` is a string value. We'll change this later on but for our initial analysis let's "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below Code Block Explanation**: This block processes the emp_length column, converting it to numeric values and handling missing data. It then creates a crosstab of emp_length_cleaned and loan_status_grouped_kn, calculates the percentage distribution of loan statuses for each employment length, and formats these percentages to two decimal places with a percentage sign. The resulting table (emp_length_percentage) shows the loan status distribution across different employment lengths, sorted in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the option to handle future downcasting behavior\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Replace NaN values in emp_length with None and convert to integer values\n",
    "df['emp_length_cleaned'] = df['emp_length'].replace({\n",
    "    '10+ years': 10,\n",
    "    '9 years': 9, '8 years': 8, '7 years': 7, '6 years': 6, '5 years': 5,\n",
    "    '4 years': 4, '3 years': 3, '2 years': 2, '1 year': 1, '< 1 year': 0,\n",
    "    'n/a': None  # Assuming 'n/a' represents missing values\n",
    "}).astype('Int64')  # Use 'Int64' for integer with support for NaN\n",
    "\n",
    "# Drop any NaN values in emp_length_cleaned if necessary\n",
    "df = df.dropna(subset=['emp_length_cleaned'])\n",
    "\n",
    "# Create a crosstab of loan_status_grouped_kn and emp_length_cleaned\n",
    "emp_length_counts = pd.crosstab(df['emp_length_cleaned'], df['loan_status_grouped_kn'])\n",
    "\n",
    "# Calculate the percentage for each loan status within each employment length year\n",
    "emp_length_percentage = emp_length_counts.div(emp_length_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Sort the index of emp_length_percentage in descending order\n",
    "emp_length_percentage = emp_length_percentage.sort_index(ascending=False)\n",
    "\n",
    "# Format each column to two decimal places with a % sign using map\n",
    "for col in emp_length_percentage.columns:\n",
    "    emp_length_percentage[col] = emp_length_percentage[col].map(lambda x: f\"{x:.2f} %\")\n",
    "\n",
    "# Display the resulting table\n",
    "emp_length_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've finised our EDA let's check some of the categorical points with our target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Newly created columns\n",
    "new_columns = ['emp_length_cleaned']  # Replace with columns name\n",
    "\n",
    "# Add new columns to feature_list if they're not already in the list\n",
    "feature_list.extend([col for col in new_columns if col not in feature_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below Code Block Explanation**: This block generates a cross-tabulation between loan_status_grouped_kn (loan status) and purpose. It uses pd.crosstab() to calculate the number of loans for each combination of loan status and loan purpose, resulting in a summary table (comparison_loan_status_purpose). This table provides insight into how different loan purposes relate to loan outcomes, helping to identify patterns between the purpose of the loan and its status (e.g., \"Paid Loan\" or \"Defaulted Loan\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cross-tabulation of purpose and loan_status\n",
    "comparison_loan_status_purpose = pd.crosstab(df['loan_status_grouped_kn'], df['purpose'])\n",
    "\n",
    "# Display the result\n",
    "comparison_loan_status_purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below Code Block Explanation**: This block sorts loan purposes by total loan counts across all statuses in descending order. It then creates a stacked bar chart to visualize the distribution of loan statuses for each purpose (comparison_loan_status_purpose_sorted). Labels and a title are added for clarity, and x-axis labels are rotated for readability. The stacked chart helps highlight how each loan status (e.g., \"Paid Loan\" or \"Defaulted Loan\") contributes to the total loan count for each purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by total loan counts across all statuses for each purpose (descending order)\n",
    "sorted_data = comparison_loan_status_purpose.sum(axis=0).sort_values(ascending=False)\n",
    "sorted_columns = sorted_data.index\n",
    "comparison_loan_status_purpose_sorted = comparison_loan_status_purpose[sorted_columns]\n",
    "\n",
    "# Plot a stacked bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot each loan status as a stacked segment\n",
    "comparison_loan_status_purpose_sorted.T.plot(kind='bar', stacked=True, ax=ax)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Purpose')\n",
    "ax.set_ylabel('Number of Loans')\n",
    "ax.set_title('Distribution of Loan Statuses by Loan Purpose')\n",
    "\n",
    "# Rotate x-axis labels for readability\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.legend(title='Loan Status')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below Code Block Explanation**: This block generates a cross-tabulation between loan_status_grouped_kn (loan status) and verification_status. Using pd.crosstab(), it calculates the count of loans for each combination of loan status and verification status, resulting in a summary table (comparison_loan_status_ver_status). This table helps in understanding the distribution of different loan statuses (e.g., \"Paid Loan\" or \"Defaulted Loan\") across various verification statuses, providing insights into how verification affects loan outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cross-tabulation of purpose and loan_status\n",
    "comparison_loan_status_ver_status = pd.crosstab(df['loan_status_grouped_kn'], df['verification_status'])\n",
    "\n",
    "# Display the result\n",
    "comparison_loan_status_ver_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below Code Block Explanation**: This block visualizes the distribution of loan statuses (loan_status_grouped_kn) across different verification statuses using a stacked bar chart. It first transposes the comparison_loan_status_ver_status DataFrame for easier plotting of the different loan statuses as stacked segments for each verification status. The chart is labeled with appropriate axis labels (Verification Status and Number of Loans) and a title (Distribution of Loan Statuses by Verification Status). The x-axis labels are rotated for better readability, and tight_layout() ensures that all elements fit properly within the figure. A legend is included to indicate the different loan statuses in the stacked bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot a stacked bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Transpose the DataFrame for easier plotting and plot each loan status as a stacked segment\n",
    "comparison_loan_status_ver_status.T.plot(kind='bar', stacked=True, ax=ax)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Verification Status')\n",
    "ax.set_ylabel('Number of Loans')\n",
    "ax.set_title('Distribution of Loan Statuses by Verification Status')\n",
    "\n",
    "# Rotate x-axis labels for readability\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.legend(title='Loan Status')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an interesting view, as the the Not Verified, and Source Verified represent both roughly 15-20% of the charged off loans for each status but Verified accounts for roughly 23% of the total. I was expecting a lot of the Charged Off in the Not Verified `verification_status`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below Code Block Explanation**: This block creates a cross-tabulation between loan_status_grouped_kn (loan status) and addr_state (state). It uses pd.crosstab() to count the number of loans for each combination of loan status and state, providing a summary table that shows how loan statuses (such as \"Paid Loan\" or \"Defaulted Loan\") are distributed across different states. The resulting DataFrame, comparison_loan_status_addr_state, helps in understanding patterns or variations in loan outcomes by geographic location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cross-tabulation of purpose and loan_status\n",
    "comparison_loan_status_addr_state = pd.crosstab(df['loan_status_grouped_kn'], df['addr_state'])\n",
    "\n",
    "# Display the result\n",
    "comparison_loan_status_addr_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below Code Block Explanation**: This block visualizes the number of defaulted loans by state. It first filters the data to only include loans with a Defaulted Loan status and sorts the states in descending order based on the number of defaulted loans. A bar plot is then generated to display this information, using salmon-colored bars for better visual appeal. The plot includes labels for the x-axis (State) and y-axis (Number of Defaulted Loans), as well as a title. The x-axis labels are rotated for readability, and tight_layout() is applied to ensure the plot elements fit well within the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data to only include the 'Defaulted' loan status\n",
    "defaulted_by_state = comparison_loan_status_addr_state.loc['Defaulted Loan']\n",
    "\n",
    "# Sort the data by the number of defaulted loans in descending order\n",
    "defaulted_by_state_sorted = defaulted_by_state.sort_values(ascending=False)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(12, 8))\n",
    "defaulted_by_state_sorted.plot(kind='bar', color='salmon', edgecolor='black')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel(\"State\")\n",
    "plt.ylabel(\"Number of Defaulted Loans\")\n",
    "plt.title(\"Number of Defaulted Loans by State (Sorted)\")\n",
    "\n",
    "# Rotate x-axis labels for readability\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Group data by 'loan_status' and 'addr_state' and count occurrences\n",
    "grouped_data = df.groupby(['addr_state', 'loan_status_grouped_kn']).size().unstack()\n",
    "\n",
    "# Sort the data by the total count of loan statuses in descending order\n",
    "grouped_data = grouped_data.loc[grouped_data.sum(axis=1).sort_values(ascending=False).index]\n",
    "\n",
    "# Plot the bar chart\n",
    "grouped_data.plot(kind='bar', stacked=True, figsize=(10, 7))\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Loan Status by Address State')\n",
    "plt.xlabel('Address State')\n",
    "plt.ylabel('Count of Loan Status')\n",
    "plt.legend(title='Loan Status')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below Code Block Explanation**: This block calculates and displays the percentage of loans that defaulted for each state. It first calculates the total number of loans for each state and then extracts the number of loans that defaulted. The percentage of defaulted loans is calculated by dividing the number of defaulted loans by the total number of loans for each state, multiplying by 100. Finally, a DataFrame is created to combine the total loans, defaulted loans, and percentage of defaulted loans for easy viewing, sorted by the percentage of defaulted loans in descending order to highlight states with the highest default rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of loans for each state\n",
    "total_loans_by_state = comparison_loan_status_addr_state.sum(axis=0)\n",
    "\n",
    "# Extract the number of defaulted loans for each state\n",
    "defaulted_loans_by_state = comparison_loan_status_addr_state.loc['Defaulted Loan']\n",
    "\n",
    "# Calculate the percentage of defaulted loans\n",
    "defaulted_percentage_by_state = (defaulted_loans_by_state / total_loans_by_state) * 100\n",
    "\n",
    "# Combine into a DataFrame for easy viewing\n",
    "defaulted_percentage_df = pd.DataFrame({\n",
    "    'Total Loans': total_loans_by_state,\n",
    "    'Defaulted Loans': defaulted_loans_by_state,\n",
    "    '% Defaulted': defaulted_percentage_by_state\n",
    "})\n",
    "\n",
    "# Display the result\n",
    "defaulted_percentage_df = defaulted_percentage_df.sort_values(by='% Defaulted', ascending=False)\n",
    "defaulted_percentage_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key Observations\n",
    "- **Top States**: The states with the highest loan counts include **CA (California)**, **TX (Texas)**, **NY (New York)**, and **FL (Florida)**. These states exhibit a high volume of loans, likely due to their larger populations and economic activities.\n",
    "- **Completed Loans**: The **Completed** loan status (blue segment) constitutes a significant portion in most states, suggesting a high rate of loan completion across regions.\n",
    "- **In Progress Loans**: The **In Progress** loan status (green segment) appears prominently in states with higher loan volumes, indicating ongoing loan activities.\n",
    "- **Defaulted and Late Loans**: **Defaulted** (orange) and **Late** (red) loans make up smaller portions of the overall loan distribution. However, states with higher loan counts (e.g., CA, TX, NY) also show relatively higher counts in these categories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data split for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_frame(features_list, df):\n",
    "    \"\"\"\n",
    "    Splits the provided DataFrame into three lists containing Boolean, Numerical, and Categorical column names.\n",
    "    Converts floats with trailing zeros into integers and replaces NaN values with 0 for integers, 0.00 for floats.\n",
    "\n",
    "    Parameters:\n",
    "    features_list (list): List of column names to be checked.\n",
    "    df (pd.DataFrame): The input DataFrame to split.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing three lists (boolean_cols, numerical_cols, categorical_cols).\n",
    "    \"\"\"\n",
    "    boolean_cols = []\n",
    "    numerical_cols = []\n",
    "    categorical_cols = []\n",
    "\n",
    "    # Define acceptable boolean values\n",
    "    acceptable_boolean_values = {0, 1, True, False, 0.0, 1.0}\n",
    "\n",
    "    for col in features_list:\n",
    "        # Treat each column explicitly as a Series\n",
    "        column_series = df[col]\n",
    "\n",
    "        # Handle cases where columns might be interpreted incorrectly\n",
    "        if pd.api.types.is_bool_dtype(column_series) or all(column_series.dropna().isin(acceptable_boolean_values)):\n",
    "            boolean_cols.append(col)\n",
    "        elif pd.api.types.is_numeric_dtype(column_series):\n",
    "            # Check for floats with trailing zeros\n",
    "            if column_series.dtype == 'float64':\n",
    "                # Check if all float values are equivalent to integers\n",
    "                if all(column_series.dropna() == column_series.dropna().astype(int)):\n",
    "                    df[col] = column_series.fillna(0).astype(int)  # Replace NaNs with 0 and convert to int\n",
    "                else:\n",
    "                    df[col] = column_series.fillna(0.00)  # Replace NaNs with 0.00 for floats\n",
    "                numerical_cols.append(col)\n",
    "            else:\n",
    "                df[col] = column_series.fillna(0)  # Replace NaNs with 0 for integers\n",
    "                numerical_cols.append(col)\n",
    "        else:\n",
    "            categorical_cols.append(col)\n",
    "    \n",
    "    # Print a summary of the count of columns in each list\n",
    "    print(f\"Summary of column counts:\")\n",
    "    print(f\"boolean_list contains {len(boolean_cols)} values\")\n",
    "    print(f\"numerical_list contains {len(numerical_cols)} values\")\n",
    "    print(f\"categorical_list contains {len(categorical_cols)} values\")\n",
    "    print(f\"The data frame we'll continue our analysis with contains (rows, cols) {df[feature_list].shape} rows and columns.\")\n",
    "\n",
    "    return boolean_cols, numerical_cols, categorical_cols\n",
    "\n",
    "# Instructions:\n",
    "# this calls the split_data_frame function above create three lists to capture the sorting outputs in. \n",
    "# These will later be used to pull some graphs to evaluate the data and what possible transformations we've missed.\n",
    "# boolean_list, numerical_list, categorical_list = split_data_frame(new_features, df_dropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_list, numerical_list, categorical_list = split_data_frame(feature_list, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df[feature_list].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[boolean_list].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[numerical_list].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[categorical_list].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Value Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below code Block Explanation**: This block identifies columns with missing values and sorts them in descending order by count. It provides a clear view of the extent of missing data, aiding decisions on handling or imputing missing values based on the proportion of NaNs in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Missing Values\n",
    "nan_list = df_clean.isna().sum()\n",
    "if nan_list.sum() == 0:\n",
    "    print(\"No column has NaN values\")\n",
    "else:\n",
    "    print(\"Columns with NaN values (sorted high to low):\")\n",
    "    print(nan_list[nan_list > 0].sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_missing_value_analysis(df, feature_list, target_column='loan_status_grouped_kn'):\n",
    "    # Check if there are any missing values in the specified columns\n",
    "    missing_cols = [col for col in feature_list if df[col].isnull().any()]\n",
    "    if not missing_cols:\n",
    "        print(\"There are no null values to analyse. Implying that NaN values have been transformed (0, mean, median, mode, etc.).\")\n",
    "        return\n",
    "\n",
    "    # Initialize dictionaries to store results for plotting\n",
    "    missing_dict = {}\n",
    "    not_missing_dict = {}\n",
    "\n",
    "    # Function to collect percentages for missing and non-missing data\n",
    "    def missing_value_analysis(column):\n",
    "        missing = df[df[column].isnull()][target_column].value_counts(normalize=True) * 100\n",
    "        not_missing = df[df[column].notnull()][target_column].value_counts(normalize=True) * 100\n",
    "        missing_dict[column] = missing\n",
    "        not_missing_dict[column] = not_missing\n",
    "\n",
    "    # Apply the function for all columns in missing_cols\n",
    "    for col in missing_cols:\n",
    "        missing_value_analysis(col)\n",
    "\n",
    "    # Create DataFrames for heatmaps\n",
    "    missing_df = pd.DataFrame(missing_dict).fillna(0)  # Fill NaN with 0 for heatmap display\n",
    "    not_missing_df = pd.DataFrame(not_missing_dict).fillna(0)\n",
    "\n",
    "    # Plotting heatmaps one below the other\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(12, 16), gridspec_kw={'height_ratios': [1, 1]})  # Adjust aspect ratio\n",
    "\n",
    "    # Heatmap for missing data\n",
    "    sns.heatmap(missing_df, annot=False, cmap=\"Blues\", ax=ax[0], cbar_kws={\"shrink\": .75})\n",
    "    ax[0].set_title('Percentage of Loan Status for Missing Data')\n",
    "    ax[0].tick_params(axis='x', rotation=90, labelsize=10)  # Rotate x-axis labels for readability\n",
    "    ax[0].tick_params(axis='y', labelsize=10)  # Adjust y-axis label size\n",
    "\n",
    "    # Heatmap for non-missing data\n",
    "    sns.heatmap(not_missing_df, annot=False, cmap=\"Greens\", ax=ax[1], cbar_kws={\"shrink\": .75})\n",
    "    ax[1].set_title('Percentage of Loan Status for Non-Missing Data')\n",
    "    ax[1].tick_params(axis='x', rotation=90, labelsize=10)  # Rotate x-axis labels for readability\n",
    "    ax[1].tick_params(axis='y', labelsize=10)  # Adjust y-axis label size\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# plot_missing_value_analysis(df, numerical_list, target_column='loan_status_grouped_kn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['loan_status_grouped_kn'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_missing_value_analysis(df_clean, categorical_list, target_column='loan_status_grouped_kn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_missing_value_analysis(df_clean, numerical_list, target_column='loan_status_grouped_kn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "\n",
    "def visualize_missing_data(df, feature_list):\n",
    "    \"\"\"\n",
    "    Visualize missing data in specified columns of a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame to analyze.\n",
    "    - feature_list (list): List of columns to check for missing values.\n",
    "\n",
    "    Returns:\n",
    "    - None. Displays visualizations of missing data if present.\n",
    "    \"\"\"\n",
    "    # Identify columns from feature_list with missing values\n",
    "    missing_values = df[feature_list].isnull().sum()\n",
    "    missing_cols = missing_values[missing_values > 0].index\n",
    "\n",
    "    # Check if there are any missing values to display\n",
    "    if not missing_cols.empty:\n",
    "        print(\"Categorical Data Missing Values\\n\")\n",
    "        \n",
    "        # Filter DataFrame to include only columns with missing values\n",
    "        missing_values_graph = df[missing_cols]\n",
    "        \n",
    "        # Visualize the missing data using the missingno library\n",
    "        msno.matrix(missing_values_graph)\n",
    "        msno.bar(missing_values_graph)\n",
    "        msno.heatmap(missing_values_graph)\n",
    "    else:\n",
    "        print(\"No columns with missing values found in the specified feature list.\")\n",
    "\n",
    "# Example usage\n",
    "# visualize_missing_data(df, feature_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_missing_data(df, categorical_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the missing data using the missingno library\n",
    "msno.matrix(df)\n",
    "msno.bar(df)\n",
    "msno.heatmap(df)\n",
    "# msno.dendrogram(missing_values_graph) #removed for the final anlysis to avoid cluttering the document with the same data but a different way to show it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below code Block Explanation**: This block generates binary indicators for missing values across columns, adding additional columns to flag where data was missing. These indicators can sometimes be useful as features, helping models understand data patterns related to missingness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Missing Data Indicators for Categorical Columns\n",
    "def create_missing_indicators(df):\n",
    "    missing_indicators = pd.DataFrame(index=df.index)  # Create an empty DataFrame to store missing indicators\n",
    "    \n",
    "    # Loop through all columns in df\n",
    "    for col in df.columns:\n",
    "        # Check if column is categorical\n",
    "        if df[col].dtype == 'object':\n",
    "            # Create missing indicator for the categorical column\n",
    "            missing_indicators[f\"{col}_missing\"] = df[col].isna().astype(int)\n",
    "    \n",
    "    # Concatenate the original DataFrame with the missing indicators\n",
    "    df_with_indicators = pd.concat([df, missing_indicators], axis=1)\n",
    "    \n",
    "    return df_with_indicators\n",
    "\n",
    "# Run the function on the DataFrame to create missing indicators for categorical columns\n",
    "df_with_missing_indicators = create_missing_indicators(df)\n",
    "\n",
    "# Display the first few rows of the resulting DataFrame\n",
    "print(df_with_missing_indicators.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below code Block Explanation**: This block preprocesses categorical variables by filling missing values with \"Other\" and applying binary encoding. Binary encoding is used here to handle high-cardinality categorical features efficiently, making the encoded features suitable for machine learning models. The target column (loan_status) is excluded from encoding to avoid unintended transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Categorical Variables with Progress Bar\n",
    "categorical_columns = [col for col in df_with_missing_indicators.select_dtypes(include=['object', 'category']).columns if col != 'loan_status']\n",
    "for col in tqdm(categorical_columns, desc=\"Filling missing values in categorical columns\"):\n",
    "    df[categorical_columns] = df[categorical_columns].fillna(\"Other\")\n",
    "\n",
    "binary_encoder = ce.BinaryEncoder(cols=categorical_columns, drop_invariant=True)\n",
    "X_encoded = binary_encoder.fit_transform(df.drop(columns=['loan_status']))\n",
    "\n",
    "print(f\"DataFrame shape after categorical preprocessing: {X_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below code Block Explanation**: This code fills any remaining missing values in numerical columns with zero, ensuring there are no NaN values in the dataset, which might disrupt model training. This imputation method may not be suitable for all cases but is quick for models that handle sparse data well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Missing Numerical Values with Progress Bar\n",
    "X_encoded = X_encoded.select_dtypes(include=['number']).columns\n",
    "for col in tqdm(X_encoded, desc=\"Imputing missing numerical values\"):\n",
    "    df[col] = df[col].fillna(0)\n",
    "\n",
    "print(f\"DataFrame shape after numerical preprocessing: {X_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below code Block Explanation**: This function checks the DataFrame for infinite values, which can disrupt calculations and model training. If any columns contain infinite values, it lists them; otherwise, it confirms no infinite values exist. This is a helpful quality check step before proceeding with further data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Infinite Values\n",
    "def check_infinity(df):\n",
    "    try:\n",
    "        # Apply np.isinf only to numeric columns\n",
    "        numeric_cols = df.select_dtypes(include=[np.number])\n",
    "        infinite_mask = np.isinf(numeric_cols)\n",
    "        infinite_list = infinite_mask.sum()\n",
    "        if infinite_list.sum() == 0:\n",
    "            print(\"No column has infinite values\")\n",
    "        else:\n",
    "            print(\"Columns with infinite values:\")\n",
    "            print(infinite_list[infinite_list > 0].sort_values(ascending=False))\n",
    "    except Exception as e:\n",
    "        # Identify the columns that may be causing the error\n",
    "        problematic_cols = []\n",
    "        for col in df.columns:\n",
    "            try:\n",
    "                np.isinf(df[col])\n",
    "            except TypeError:\n",
    "                problematic_cols.append(col)\n",
    "        \n",
    "        print(f\"An error occurred while checking for infinite values: {e}\")\n",
    "        if problematic_cols:\n",
    "            print(f\"The following columns may be causing the issue due to incompatible types: {problematic_cols}\")\n",
    "\n",
    "check_infinity(X_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below code Block Explanation**: Here, X and y are defined as the feature matrix and target variable, respectively. The data is then split into training and testing sets, reserving 20% of the data for testing. This separation is essential for evaluating model performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that X_encoded and y are aligned\n",
    "assert len(X_encoded) == len(df), \"Mismatch between X_encoded and df, ensure they are aligned before splitting.\"\n",
    "\n",
    "# Define X and y Variables\n",
    "X = X_encoded\n",
    "y = df['loan_status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below code Block Explanation**: The target variable (loan_status) is label-encoded to convert categorical values into numeric labels, which are necessary for most machine learning algorithms. This step ensures compatibility with scikit-learns models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Target Variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below code Block Explanation**: This block calculates the Variance Inflation Factor (VIF) for each feature to assess multicollinearity. High VIF values indicate high correlation among predictors, which can affect model stability and interpretability. This information guides the removal of redundant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Missing or Infinite Values in DataFrame\n",
    "def check_missing_or_infinite(df):\n",
    "    columns_with_issues = []\n",
    "    for col in df.columns:\n",
    "        # Only process columns if they are numeric\n",
    "        if df[col].dtype in [np.float64, np.float32, np.int64, np.int32]:\n",
    "            if df[col].isna().any() or np.isinf(df[col]).any():\n",
    "                columns_with_issues.append(col)\n",
    "\n",
    "    if len(columns_with_issues) > 0:\n",
    "        print(f\"The following columns contain NaN or infinite values: {columns_with_issues}\")\n",
    "    else:\n",
    "        print(\"No columns contain NaN or infinite values.\")\n",
    "\n",
    "# Run the check on X_encoded before calculating VIF\n",
    "check_missing_or_infinite(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded[['dti', 'mths_since_last_delinq', 'mths_since_last_record', 'collections_12_mths_ex_med', 'mths_since_last_major_derog', 'annual_inc_joint', 'dti_joint', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m', 'open_act_il', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m', 'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_bc_dlq', 'mths_since_recent_inq', 'mths_since_recent_revol_delinq', 'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl', 'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m', 'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', 'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies', 'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit', 'total_il_high_credit_limit', 'revol_bal_joint', 'sec_app_fico_range_low', 'sec_app_fico_range_high', 'sec_app_inq_last_6mths', 'sec_app_mort_acc', 'sec_app_open_acc', 'sec_app_revol_util', 'sec_app_open_act_il', 'sec_app_num_rev_accts', 'sec_app_chargeoff_within_12_mths', 'sec_app_collections_12_mths_ex_med', 'deferral_term', 'hardship_amount', 'hardship_length', 'hardship_dpd', 'orig_projected_additional_accrued_interest', 'hardship_payoff_balance_amount', 'hardship_last_payment_amount']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded[['dti', 'mths_since_last_delinq', 'mths_since_last_record', 'collections_12_mths_ex_med', 'mths_since_last_major_derog', 'annual_inc_joint', 'dti_joint', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m', 'open_act_il', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m', 'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_bc_dlq', 'mths_since_recent_inq', 'mths_since_recent_revol_delinq', 'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl', 'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m', 'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', 'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies', 'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit', 'total_il_high_credit_limit', 'revol_bal_joint', 'sec_app_fico_range_low', 'sec_app_fico_range_high', 'sec_app_inq_last_6mths', 'sec_app_mort_acc', 'sec_app_open_acc', 'sec_app_revol_util', 'sec_app_open_act_il', 'sec_app_num_rev_accts', 'sec_app_chargeoff_within_12_mths', 'sec_app_collections_12_mths_ex_med', 'deferral_term', 'hardship_amount', 'hardship_length', 'hardship_dpd', 'orig_projected_additional_accrued_interest', 'hardship_payoff_balance_amount', 'hardship_last_payment_amount']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate VIF with Progress Bar\n",
    "def calculate_vif(X):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [\n",
    "        variance_inflation_factor(X.values, i) for i in tqdm(range(X.shape[1]), desc=\"Calculating VIF\")\n",
    "    ]\n",
    "    return vif_data\n",
    "\n",
    "# Calculate VIF for the original DataFrame\n",
    "vif_data_original = calculate_vif(X_encoded)\n",
    "\n",
    "# Remove features with high VIF\n",
    "high_vif_features = vif_data_original[vif_data_original[\"VIF\"] > 5][\"feature\"].tolist()\n",
    "X_encoded = X_encoded.drop(columns=high_vif_features)\n",
    "\n",
    "# Calculate VIF and print results for missing data indicators\n",
    "missing_indicators_columns = [col for col in X_encoded.columns if '_missing' in col]\n",
    "vif_data_missing = calculate_vif(X_encoded[missing_indicators_columns])\n",
    "print(\"VIF for missing data indicators:\\n\", vif_data_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below code Block Explanation**: This block removes features with a VIF above 5, indicating high collinearity. By filtering out these features, we reduce redundancy, making the feature set more interpretable and less prone to multicollinearity issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove High-VIF Features\n",
    "high_vif_features = vif_data[vif_data[\"VIF\"] > 5][\"feature\"].tolist()\n",
    "X_vif_reduced = X.drop(columns=high_vif_features)\n",
    "print(\"\\nFeatures remaining after VIF filtering:\\n\", X_vif_reduced.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below code Block Explanation**: Using Recursive Feature Elimination (RFE) with a linear regression model, this block selects the top 5 most informative features from the reduced feature set (X_vif_reduced). RFE iteratively removes the least important features based on the model's criteria, improving model efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination (RFE)\n",
    "model = LinearRegression()\n",
    "rfe = RFE(estimator=model, n_features_to_select=5)\n",
    "X_rfe_reduced = rfe.fit_transform(X_vif_reduced, y)\n",
    "\n",
    "selected_features = X_vif_reduced.columns[rfe.support_]\n",
    "print(\"\\nFeatures selected by RFE:\\n\", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below code Block Explanation**: This final block applies RFE using a RandomForestClassifier on numerical columns. The model selects 48 features and eliminates 18 in each iteration, focusing on numerical features only. The selected features from RandomForest RFE are displayed, providing insight into the most informative numerical predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest RFE for Numerical Columns\n",
    "rf = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "rfe = RFE(estimator=rf, n_features_to_select=48, step=18, verbose=3)\n",
    "X_train_numerical = X_train.select_dtypes(include=['number'])\n",
    "rfe.fit(X_train_numerical, y_train)\n",
    "\n",
    "selected_features_rf = X_train_numerical.columns[rfe.support_]\n",
    "print(\"\\nNumerical Features selected by RandomForest RFE:\\n\", selected_features_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below code Block Explanation**: Models we'll run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Define a dictionary of models to evaluate\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    \"Support Vector Machine\": SVC(probability=True, random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(silent=True, random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below code Block Explanation**: This block evaluates multiple models in a dictionary called models using a progress bar to track completion. For each model, it chooses the correct evaluation function (evaluate_model_multi or evaluate_model_single) based on the multi_class_strategy parameter. If models is not defined, it provides an alert to avoid errors. The results from each evaluation are stored in a list for later review or analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating models based on user selection with progress bar\n",
    "results = []\n",
    "if models is not None:\n",
    "    for name, model in tqdm(models.items(), desc=\"Evaluating models\"):\n",
    "        # Choose the correct evaluation function based on model type\n",
    "        if multi_class_strategy:\n",
    "            result = evaluate_model_multi(\n",
    "                name, model, X_train, X_test, y_train, y_test,\n",
    "                save_path=SAVE_PATH,\n",
    "                multi_class_strategy=multi_class_strategy  # Pass strategy to evaluation function\n",
    "            )\n",
    "        else:\n",
    "            result = evaluate_model_single(\n",
    "                name, model, X_train, X_test, y_train, y_test,\n",
    "                save_path=SAVE_PATH\n",
    "            )\n",
    "            \n",
    "        results.append(result)\n",
    "else:\n",
    "    print(\"Model evaluation was not performed due to invalid selection.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below code Block Explanation**: This block converts the list of evaluation results into a DataFrame for a clear summary and displays it. It optionally saves the results to a CSV file, making it easier to analyze or share the performance metrics across different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results list to a DataFrame for better visualization and analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nEvaluation Results Summary:\")\n",
    "print(results_df)\n",
    "\n",
    "# Optionally, save results to a CSV file\n",
    "results_df.to_csv(f\"{SAVE_PATH}/model_evaluation_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below code Block Explanation**: This block generates a line plot to compare different performance metrics across models. Each line represents a metric, such as accuracy or F1-score, helping identify which model performs best in each area. This visualization is valuable for quickly assessing model strengths and trade-offs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `results` is the list of dictionaries created by the model evaluation function\n",
    "# Convert the list of results into a DataFrame for tabular display\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display results as a table for easy comparison\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "display(results_df)  # If running in a Jupyter notebook, this will display a nice formatted table\n",
    "\n",
    "# Visualize Performance Comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Cross-Validation Mean Accuracy']\n",
    "\n",
    "# Plot each metric for all models\n",
    "for metric in metrics:\n",
    "    plt.plot(results_df['Model'], results_df[metric], marker='o', label=metric)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Model Performance Comparison\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below code Block Explanation**: This block saves each model to disk, enabling easy reuse without retraining. Each model is saved with a descriptive filename, storing it in the specified SAVE_PATH. This is especially useful when working with multiple models and allows for future analysis or deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save All Models for Future Use\n",
    "for name, model in models.items():\n",
    "    joblib.dump(model, f\"{SAVE_PATH}/{name}_final_model.pkl\")\n",
    "print(\"\\nAll models have been saved for future use.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SHAP Explanations for Model Interpretability ===\n",
    "import shap\n",
    "\n",
    "# Initialize SHAP Explainer for each model\n",
    "def explain_model_with_shap(model, X_sample, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Generates SHAP explanations for the given model and dataset sample.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    model : estimator object\n",
    "        The trained model to explain.\n",
    "    X_sample : DataFrame\n",
    "        A sample of the dataset to generate SHAP values for.\n",
    "    model_name : str\n",
    "        Name of the model for display in plots.\n",
    "    \"\"\"\n",
    "    print(f\"\\nGenerating SHAP explanations for {model_name}...\")\n",
    "    \n",
    "    # Use SHAP's TreeExplainer for tree-based models (e.g., RandomForest, XGBoost, LightGBM)\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        explainer = shap.Explainer(model, X_sample, check_additivity=False)\n",
    "    else:\n",
    "        explainer = shap.Explainer(model)\n",
    "    \n",
    "    # Calculate SHAP values\n",
    "    shap_values = explainer(X_sample)\n",
    "\n",
    "    # Plot feature importance summary\n",
    "    shap.summary_plot(shap_values, X_sample, plot_type=\"bar\", show=True)\n",
    "    \n",
    "    # Detailed summary plot with individual SHAP values per feature and instance\n",
    "    shap.summary_plot(shap_values, X_sample, show=True)\n",
    "\n",
    "    # Example force plot for the first prediction (requires a single instance)\n",
    "    shap.force_plot(explainer.expected_value, shap_values[0, :], X_sample.iloc[0, :], matplotlib=True)\n",
    "\n",
    "\n",
    "# Choose a subset of data to explain (e.g., a random sample of 100 rows)\n",
    "X_sample = X_test.sample(100, random_state=42)\n",
    "\n",
    "# Explain the main trained model (example: RandomForestClassifier)\n",
    "explain_model_with_shap(RandomForestClassifier, X_sample, model_name=\"RandomForestClassifier\")\n",
    "\n",
    "# Loop to explain all models in a dictionary (if multiple models)\n",
    "for name, model in models.items():\n",
    "    explain_model_with_shap(model, X_sample, model_name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
