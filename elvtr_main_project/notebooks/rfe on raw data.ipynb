{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline - Clean Code Version\n",
    "\n",
    "This notebook demonstrates a comprehensive machine learning pipeline, including data preprocessing, feature engineering, model training, and evaluation for both binary and multi-class classification tasks. Below is an outline of each key section:\n",
    "\n",
    "1. **Library Imports**: Loads all essential libraries for data handling, visualization, model training, evaluation, and saving.\n",
    "\n",
    "2. **Data Loading and Cleaning**: Reads the dataset, standardizes column names, and applies initial data quality checks for missing and infinite values.\n",
    "\n",
    "3. **Data Preprocessing**:\n",
    "   - Categorical features are filled and encoded using binary encoding.\n",
    "   - Missing values in numerical features are imputed.\n",
    "   - Missing data indicators are created for further analysis.\n",
    "\n",
    "4. **Feature Engineering**:\n",
    "   - Calculates Variance Inflation Factor (VIF) to identify and remove features with high multicollinearity.\n",
    "   - Applies Recursive Feature Elimination (RFE) with Linear Regression and RandomForest for feature selection.\n",
    "\n",
    "5. **Multi-Class Strategy Setup**:\n",
    "   - Defines a function to wrap models in appropriate multi-class strategies (`OneVsOne` or `OneVsRest`) when applicable.\n",
    "\n",
    "6. **Model Evaluation Functions**:\n",
    "   - `evaluate_model_single`: Evaluates binary classification models, displaying ROC and Precision-Recall curves, metrics, and confusion matrix.\n",
    "   - `evaluate_model_multi`: Evaluates multi-class classification models with class-specific ROC and Precision-Recall curves.\n",
    "\n",
    "7. **Column Removal**: Removes specified columns from training and test datasets to ensure only relevant features are included in modeling.\n",
    "\n",
    "8. **Model Training and Evaluation**:\n",
    "   - Iterates over models, evaluating each based on user-defined selection and multi-class strategy, with progress tracked by a progress bar.\n",
    "   - Stores and displays the evaluation metrics, including accuracy, precision, recall, F1-score, ROC-AUC, and cross-validation accuracy.\n",
    "\n",
    "9. **Results Summary and Visualization**:\n",
    "   - Summarizes results in a DataFrame and saves them to a CSV file.\n",
    "   - Plots a comparison of performance metrics across models for quick assessment.\n",
    "\n",
    "10. **Model Saving and Reloading**:\n",
    "    - Saves all trained models to disk for future use.\n",
    "    - Demonstrates reloading saved models and making predictions to validate accuracy.\n",
    "\n",
    "This pipeline is designed to handle both binary and multi-class problems, supports multiple models, and provides detailed performance analysis and visualization for decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let the Fun Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: This block imports essential libraries required for data handling, encoding, visualization, machine learning models, feature selection, and evaluation metrics. Grouping imports helps keep the code organized, and importing them all at once avoids repetitive imports later in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kiera\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# === Import Required Libraries ===\n",
    "\n",
    "# Data Manipulation and Preprocessing\n",
    "import pandas as pd         # Core data manipulation library\n",
    "import numpy as np          # Mathematical operations\n",
    "import category_encoders as ce  # Encoding categorical variables\n",
    "\n",
    "# Statistical Analysis\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest, shapiro, anderson, kstest, skew\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor  # For multicollinearity checks (VIF)\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt         # Basic plotting\n",
    "import seaborn as sns                   # Advanced static visualizations with themes\n",
    "import plotly.express as px             # Interactive plots\n",
    "import missingno as msno                # Visualizing missing data\n",
    "\n",
    "# Data Preprocessing and Encoding\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, label_binarize  # Scaling and label encoding\n",
    "from sklearn.model_selection import train_test_split, cross_val_score           # Data splitting and cross-validation\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression           # Linear models for classification and regression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor          # Decision Tree models\n",
    "from sklearn.ensemble import (                                                 \n",
    "    RandomForestClassifier, RandomForestRegressor,                              # Random Forest models\n",
    "    GradientBoostingClassifier, GradientBoostingRegressor                       # Gradient Boosting models\n",
    ")\n",
    "from sklearn.svm import SVC, SVR                                               # Support Vector Machine for classification and regression\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor        # K-Nearest Neighbors for classification and regression\n",
    "from sklearn.naive_bayes import GaussianNB                                     # Naive Bayes for classification\n",
    "from sklearn.cluster import KMeans                                             # KMeans clustering\n",
    "from sklearn.decomposition import PCA                                          # Principal Component Analysis (PCA) for dimensionality reduction\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier         # Multi-class classification strategies\n",
    "\n",
    "# Advanced Machine Learning Models\n",
    "from xgboost import XGBClassifier         # Extreme Gradient Boosting\n",
    "from lightgbm import LGBMClassifier       # Light Gradient Boosting Machine\n",
    "from catboost import CatBoostClassifier   # CatBoost Gradient Boosting\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import RFE  # Recursive Feature Elimination (RFE) for feature selection\n",
    "\n",
    "# Model Evaluation Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,      # Basic classification metrics\n",
    "    roc_auc_score, confusion_matrix,                             # Advanced metrics and confusion matrix\n",
    "    roc_curve, precision_recall_curve, average_precision_score    # Curve metrics for model evaluation\n",
    ")\n",
    "\n",
    "# Deep Learning with TensorFlow/Keras\n",
    "from tensorflow.keras.models import Sequential          # Sequential model setup in Keras\n",
    "from tensorflow.keras.layers import Dense               # Dense layers for neural networks\n",
    "\n",
    "# Utilities\n",
    "from tqdm import tqdm       # Progress bar for loops\n",
    "import joblib               # For saving/loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: This block loads the dataset and standardizes column names by removing extra spaces, converting to lowercase, and replacing spaces with underscores for better accessibility in code. Printing the cleaned headers and the shape of the DataFrame provides a quick verification that the data has loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned headers: ['unnamed:_0.1', 'unnamed:_0', 'id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership', 'annual_inc', 'verification_status', 'issue_d', 'loan_status', 'pymnt_plan', 'url', 'purpose', 'title', 'zip_code', 'addr_state', 'dti', 'delinq_2yrs', 'earliest_cr_line', 'fico_range_low', 'fico_range_high', 'inq_last_6mths', 'mths_since_last_delinq', 'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'initial_list_status', 'out_prncp', 'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'last_pymnt_d', 'last_pymnt_amnt', 'next_pymnt_d', 'last_credit_pull_d', 'last_fico_range_high', 'last_fico_range_low', 'collections_12_mths_ex_med', 'mths_since_last_major_derog', 'policy_code', 'application_type', 'annual_inc_joint', 'dti_joint', 'verification_status_joint', 'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m', 'open_act_il', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m', 'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths', 'delinq_amnt', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_bc_dlq', 'mths_since_recent_inq', 'mths_since_recent_revol_delinq', 'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl', 'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m', 'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', 'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies', 'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit', 'total_il_high_credit_limit', 'revol_bal_joint', 'sec_app_fico_range_low', 'sec_app_fico_range_high', 'sec_app_earliest_cr_line', 'sec_app_inq_last_6mths', 'sec_app_mort_acc', 'sec_app_open_acc', 'sec_app_revol_util', 'sec_app_open_act_il', 'sec_app_num_rev_accts', 'sec_app_chargeoff_within_12_mths', 'sec_app_collections_12_mths_ex_med', 'hardship_flag', 'hardship_type', 'hardship_reason', 'hardship_status', 'deferral_term', 'hardship_amount', 'hardship_start_date', 'hardship_end_date', 'payment_plan_start_date', 'hardship_length', 'hardship_dpd', 'hardship_loan_status', 'orig_projected_additional_accrued_interest', 'hardship_payoff_balance_amount', 'hardship_last_payment_amount', 'debt_settlement_flag']\n",
      "(100000, 143)\n"
     ]
    }
   ],
   "source": [
    "# Load and Clean Data\n",
    "df = pd.read_csv(\"c:\\\\Users\\\\kiera\\\\OneDrive\\\\Documents\\\\GitHub\\\\dsif-git-main-project\\\\elvtr_main_project\\\\data\\\\1-raw\\\\lending-club-2007-2020Q3\\\\Loan_status_2007-2020Q3-100ksample.csv\")\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "print(\"Cleaned headers:\", df.columns.tolist())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: Here, the display options for pandas are set to show all columns and rows, which is useful during data exploration to get a complete view. Additionally, a white grid theme is applied to Seaborn plots, providing a consistent look for visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration and Display Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "sns.set_theme(style='whitegrid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: This block identifies columns with missing values and sorts them in descending order by count. It provides a clear view of the extent of missing data, aiding decisions on handling or imputing missing values based on the proportion of NaNs in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN values (sorted high to low):\n",
      "hardship_loan_status                          95116\n",
      "hardship_end_date                             95105\n",
      "deferral_term                                 95105\n",
      "hardship_status                               95105\n",
      "hardship_dpd                                  95105\n",
      "hardship_reason                               95105\n",
      "hardship_length                               95105\n",
      "payment_plan_start_date                       95105\n",
      "hardship_type                                 95105\n",
      "hardship_start_date                           95105\n",
      "orig_projected_additional_accrued_interest    93873\n",
      "hardship_last_payment_amount                  93778\n",
      "hardship_payoff_balance_amount                93778\n",
      "hardship_amount                               93778\n",
      "sec_app_revol_util                            93387\n",
      "verification_status_joint                     93369\n",
      "revol_bal_joint                               93261\n",
      "sec_app_open_acc                              93260\n",
      "sec_app_open_act_il                           93260\n",
      "sec_app_num_rev_accts                         93260\n",
      "sec_app_chargeoff_within_12_mths              93260\n",
      "sec_app_collections_12_mths_ex_med            93260\n",
      "sec_app_mort_acc                              93260\n",
      "sec_app_inq_last_6mths                        93260\n",
      "sec_app_earliest_cr_line                      93260\n",
      "sec_app_fico_range_high                       93260\n",
      "sec_app_fico_range_low                        93260\n",
      "annual_inc_joint                              92834\n",
      "dti_joint                                     92834\n",
      "mths_since_last_record                        85370\n",
      "mths_since_recent_bc_dlq                      78057\n",
      "mths_since_last_major_derog                   75398\n",
      "mths_since_recent_revol_delinq                68342\n",
      "next_pymnt_d                                  63573\n",
      "mths_since_last_delinq                        52814\n",
      "il_util                                       39685\n",
      "mths_since_rcnt_il                            31773\n",
      "all_util                                      29657\n",
      "open_acc_6m                                   29644\n",
      "open_act_il                                   29644\n",
      "max_bal_bc                                    29644\n",
      "open_il_12m                                   29644\n",
      "open_il_24m                                   29644\n",
      "total_bal_il                                  29644\n",
      "open_rv_12m                                   29644\n",
      "inq_last_12m                                  29644\n",
      "total_cu_tl                                   29644\n",
      "inq_fi                                        29644\n",
      "open_rv_24m                                   29644\n",
      "mths_since_recent_inq                         12810\n",
      "emp_title                                      8954\n",
      "emp_length                                     6950\n",
      "num_tl_120dpd_2m                               5512\n",
      "mo_sin_old_il_acct                             5373\n",
      "bc_util                                        2899\n",
      "percent_bc_gt_75                               2867\n",
      "bc_open_to_buy                                 2848\n",
      "mths_since_recent_bc                           2788\n",
      "pct_tl_nvr_dlq                                 2442\n",
      "avg_cur_bal                                    2440\n",
      "total_rev_hi_lim                               2438\n",
      "num_actv_rev_tl                                2438\n",
      "tot_cur_bal                                    2438\n",
      "tot_coll_amt                                   2438\n",
      "mo_sin_old_rev_tl_op                           2438\n",
      "mo_sin_rcnt_rev_tl_op                          2438\n",
      "mo_sin_rcnt_tl                                 2438\n",
      "num_op_rev_tl                                  2438\n",
      "num_accts_ever_120_pd                          2438\n",
      "num_il_tl                                      2438\n",
      "num_tl_90g_dpd_24m                             2438\n",
      "num_tl_op_past_12m                             2438\n",
      "num_rev_accts                                  2438\n",
      "num_rev_tl_bal_gt_0                            2438\n",
      "num_tl_30dpd                                   2438\n",
      "num_bc_tl                                      2438\n",
      "num_actv_bc_tl                                 2438\n",
      "total_il_high_credit_limit                     2438\n",
      "tot_hi_cred_lim                                2438\n",
      "num_bc_sats                                    2051\n",
      "num_sats                                       2051\n",
      "mort_acc                                       1778\n",
      "acc_open_past_24mths                           1778\n",
      "total_bc_limit                                 1778\n",
      "total_bal_ex_mort                              1778\n",
      "hardship_flag                                  1327\n",
      "title                                           780\n",
      "last_pymnt_d                                    191\n",
      "dti                                             102\n",
      "revol_util                                       81\n",
      "pub_rec_bankruptcies                             45\n",
      "chargeoff_within_12_mths                          6\n",
      "collections_12_mths_ex_med                        6\n",
      "tax_liens                                         5\n",
      "last_credit_pull_d                                2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for Missing Values\n",
    "nan_list = df.isna().sum()\n",
    "if nan_list.sum() == 0:\n",
    "    print(\"No column has NaN values\")\n",
    "else:\n",
    "    print(\"Columns with NaN values (sorted high to low):\")\n",
    "    print(nan_list[nan_list > 0].sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: This block generates binary indicators for missing values across columns, adding additional columns to flag where data was missing. These indicators can sometimes be useful as features, helping models understand data patterns related to missingness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unnamed:_0.1  unnamed:_0         id  loan_amnt  funded_amnt  \\\n",
      "0       1746494       25450  167338079     4000.0       4000.0   \n",
      "1       2370717       81861   71016917    24000.0      24000.0   \n",
      "2       2264870      397109   39589826     5000.0       5000.0   \n",
      "3        595422       15492  134798709    24000.0      24000.0   \n",
      "4        562657       90591  127097355    14000.0      14000.0   \n",
      "\n",
      "   funded_amnt_inv        term int_rate  installment grade sub_grade  \\\n",
      "0           4000.0   36 months   13.08%       134.93     B        B5   \n",
      "1          24000.0   60 months    9.16%       500.07     B        B2   \n",
      "2           5000.0   36 months   10.49%       162.49     B        B3   \n",
      "3          24000.0   60 months   11.05%       522.42     B        B4   \n",
      "4          14000.0   60 months   13.59%       322.79     C        C2   \n",
      "\n",
      "        emp_title emp_length home_ownership  annual_inc verification_status  \\\n",
      "0         cashier  10+ years       MORTGAGE     48000.0     Source Verified   \n",
      "1             ABM    6 years           RENT     57000.0     Source Verified   \n",
      "2          driver  10+ years       MORTGAGE     55000.0        Not Verified   \n",
      "3             NaN        NaN       MORTGAGE     43500.0        Not Verified   \n",
      "4  Shipping Clerk  10+ years       MORTGAGE     48000.0     Source Verified   \n",
      "\n",
      "    issue_d loan_status pymnt_plan  \\\n",
      "0  Mar-2020     Current          n   \n",
      "1  Feb-2016     Current          n   \n",
      "2  Jan-2015  Fully Paid          n   \n",
      "3  Jun-2018     Current          n   \n",
      "4  Jan-2018  Fully Paid          n   \n",
      "\n",
      "                                                 url             purpose  \\\n",
      "0  https://lendingclub.com/browse/loanDetail.acti...    home_improvement   \n",
      "1  https://lendingclub.com/browse/loanDetail.acti...         credit_card   \n",
      "2  https://lendingclub.com/browse/loanDetail.acti...         credit_card   \n",
      "3  https://lendingclub.com/browse/loanDetail.acti...  debt_consolidation   \n",
      "4  https://lendingclub.com/browse/loanDetail.acti...  debt_consolidation   \n",
      "\n",
      "                     title zip_code addr_state    dti  delinq_2yrs  \\\n",
      "0         Home improvement    115xx         NY  20.25          1.0   \n",
      "1  Credit card refinancing    708xx         LA  25.33          0.0   \n",
      "2  Credit card refinancing    347xx         FL   7.22          0.0   \n",
      "3       Debt consolidation    443xx         OH  24.55          0.0   \n",
      "4       Debt consolidation    681xx         NE  24.30          0.0   \n",
      "\n",
      "  earliest_cr_line  fico_range_low  fico_range_high  inq_last_6mths  \\\n",
      "0         Dec-2004           665.0            669.0             0.0   \n",
      "1         Jan-2004           680.0            684.0             0.0   \n",
      "2         Apr-2010           665.0            669.0             0.0   \n",
      "3         Oct-2005           750.0            754.0             0.0   \n",
      "4         Apr-2008           735.0            739.0             1.0   \n",
      "\n",
      "   mths_since_last_delinq  mths_since_last_record  open_acc  pub_rec  \\\n",
      "0                    19.0                   110.0       4.0      1.0   \n",
      "1                     NaN                     NaN      10.0      0.0   \n",
      "2                     NaN                    61.0       7.0      1.0   \n",
      "3                     NaN                     NaN      15.0      0.0   \n",
      "4                     NaN                     NaN      16.0      0.0   \n",
      "\n",
      "   revol_bal revol_util  total_acc initial_list_status  out_prncp  \\\n",
      "0     1988.0      82.8%       12.0                   w    3816.34   \n",
      "1    22697.0      64.5%       24.0                   w    4333.29   \n",
      "2     6001.0      52.6%        9.0                   f       0.00   \n",
      "3     6573.0      12.1%       23.0                   w   16317.69   \n",
      "4    11894.0      27.1%       23.0                   w       0.00   \n",
      "\n",
      "   out_prncp_inv   total_pymnt  total_pymnt_inv  total_rec_prncp  \\\n",
      "0        3816.34    266.950000           266.95           183.66   \n",
      "1        4333.29  25496.160000         25496.16         19666.71   \n",
      "2           0.00   5846.672836          5846.67          5000.00   \n",
      "3       16317.69  12000.930000         12000.93          7682.31   \n",
      "4           0.00  16605.680000         16605.68         14000.00   \n",
      "\n",
      "   total_rec_int  total_rec_late_fee  recoveries  collection_recovery_fee  \\\n",
      "0          83.29                 0.0         0.0                      0.0   \n",
      "1        5829.45                 0.0         0.0                      0.0   \n",
      "2         846.67                 0.0         0.0                      0.0   \n",
      "3        4318.62                 0.0         0.0                      0.0   \n",
      "4        2605.68                 0.0         0.0                      0.0   \n",
      "\n",
      "  last_pymnt_d  last_pymnt_amnt next_pymnt_d last_credit_pull_d  \\\n",
      "0     May-2020           134.93     Jun-2020           May-2020   \n",
      "1     May-2020           500.07     Jun-2020           May-2020   \n",
      "2     Jan-2018           162.43          NaN           May-2020   \n",
      "3     May-2020           522.42     Jun-2020           May-2020   \n",
      "4     Jul-2019         11128.82          NaN           Feb-2020   \n",
      "\n",
      "   last_fico_range_high  last_fico_range_low  collections_12_mths_ex_med  \\\n",
      "0                 669.0                665.0                         1.0   \n",
      "1                 704.0                700.0                         0.0   \n",
      "2                 789.0                785.0                         0.0   \n",
      "3                 749.0                745.0                         0.0   \n",
      "4                 779.0                775.0                         0.0   \n",
      "\n",
      "   mths_since_last_major_derog  policy_code application_type  \\\n",
      "0                          NaN          1.0       Individual   \n",
      "1                          NaN          1.0       Individual   \n",
      "2                          NaN          1.0       Individual   \n",
      "3                          NaN          1.0       Individual   \n",
      "4                          NaN          1.0       Individual   \n",
      "\n",
      "   annual_inc_joint  dti_joint verification_status_joint  acc_now_delinq  \\\n",
      "0               NaN        NaN                       NaN             0.0   \n",
      "1               NaN        NaN                       NaN             0.0   \n",
      "2               NaN        NaN                       NaN             0.0   \n",
      "3               NaN        NaN                       NaN             0.0   \n",
      "4               NaN        NaN                       NaN             0.0   \n",
      "\n",
      "   tot_coll_amt  tot_cur_bal  open_acc_6m  open_act_il  open_il_12m  \\\n",
      "0        3832.0     259024.0          0.0          1.0          0.0   \n",
      "1           0.0      61815.0          0.0          3.0          0.0   \n",
      "2           0.0     159131.0          NaN          NaN          NaN   \n",
      "3           0.0     104590.0          2.0          1.0          0.0   \n",
      "4           0.0      90253.0          2.0          2.0          1.0   \n",
      "\n",
      "   open_il_24m  mths_since_rcnt_il  total_bal_il  il_util  open_rv_12m  \\\n",
      "0          1.0                16.0        9960.0     56.0          0.0   \n",
      "1          3.0                14.0       39118.0     72.0          1.0   \n",
      "2          NaN                 NaN           NaN      NaN          NaN   \n",
      "3          1.0                17.0       11947.0     60.0          2.0   \n",
      "4          1.0                 7.0       22953.0     60.0          3.0   \n",
      "\n",
      "   open_rv_24m  max_bal_bc  all_util  total_rev_hi_lim  inq_fi  total_cu_tl  \\\n",
      "0          0.0         0.0      59.0            2400.0     1.0          0.0   \n",
      "1          1.0      2137.0      67.0           35200.0     0.0          7.0   \n",
      "2          NaN         NaN       NaN           11400.0     NaN          NaN   \n",
      "3          3.0      2223.0      25.0           54500.0     2.0          0.0   \n",
      "4          4.0      3907.0      43.0           43900.0     1.0          0.0   \n",
      "\n",
      "   inq_last_12m  acc_open_past_24mths  avg_cur_bal  bc_open_to_buy  bc_util  \\\n",
      "0           0.0                   1.0      64756.0             NaN      NaN   \n",
      "1           0.0                   4.0       6182.0          7741.0     40.5   \n",
      "2           NaN                   4.0      22733.0          4521.0     54.8   \n",
      "3           2.0                   4.0       6973.0         43140.0     12.0   \n",
      "4           2.0                   5.0       5641.0         17318.0     39.9   \n",
      "\n",
      "   chargeoff_within_12_mths  delinq_amnt  mo_sin_old_il_acct  \\\n",
      "0                       0.0          0.0               179.0   \n",
      "1                       0.0          0.0               145.0   \n",
      "2                       0.0          0.0                57.0   \n",
      "3                       0.0          0.0                37.0   \n",
      "4                       0.0          0.0                72.0   \n",
      "\n",
      "   mo_sin_old_rev_tl_op  mo_sin_rcnt_rev_tl_op  mo_sin_rcnt_tl  mort_acc  \\\n",
      "0                  75.0                   38.0            16.0       2.0   \n",
      "1                 137.0                    7.0             7.0       0.0   \n",
      "2                  57.0                   14.0             9.0       1.0   \n",
      "3                 132.0                    1.0             1.0       2.0   \n",
      "4                 117.0                    6.0             6.0       2.0   \n",
      "\n",
      "   mths_since_recent_bc  mths_since_recent_bc_dlq  mths_since_recent_inq  \\\n",
      "0                   NaN                      19.0                   16.0   \n",
      "1                   7.0                       NaN                   24.0   \n",
      "2                  14.0                       NaN                    1.0   \n",
      "3                   1.0                       NaN                    3.0   \n",
      "4                   6.0                       NaN                    5.0   \n",
      "\n",
      "   mths_since_recent_revol_delinq  num_accts_ever_120_pd  num_actv_bc_tl  \\\n",
      "0                            19.0                    1.0             0.0   \n",
      "1                             NaN                    0.0             3.0   \n",
      "2                             NaN                    0.0             3.0   \n",
      "3                             NaN                    1.0             6.0   \n",
      "4                             NaN                    0.0             4.0   \n",
      "\n",
      "   num_actv_rev_tl  num_bc_sats  num_bc_tl  num_il_tl  num_op_rev_tl  \\\n",
      "0              2.0          0.0        1.0        5.0            2.0   \n",
      "1              5.0          5.0        6.0       15.0            7.0   \n",
      "2              5.0          3.0        3.0        2.0            5.0   \n",
      "3              7.0         11.0       16.0        2.0           13.0   \n",
      "4              5.0          5.0        6.0        5.0           13.0   \n",
      "\n",
      "   num_rev_accts  num_rev_tl_bal_gt_0  num_sats  num_tl_120dpd_2m  \\\n",
      "0            5.0                  2.0       4.0               0.0   \n",
      "1            9.0                  5.0      10.0               0.0   \n",
      "2            6.0                  5.0       7.0               0.0   \n",
      "3           19.0                  7.0      15.0               0.0   \n",
      "4           16.0                  5.0      16.0               0.0   \n",
      "\n",
      "   num_tl_30dpd  num_tl_90g_dpd_24m  num_tl_op_past_12m  pct_tl_nvr_dlq  \\\n",
      "0           0.0                 0.0                 0.0            75.0   \n",
      "1           0.0                 0.0                 1.0            95.8   \n",
      "2           0.0                 0.0                 1.0           100.0   \n",
      "3           0.0                 0.0                 2.0            95.7   \n",
      "4           0.0                 0.0                 4.0           100.0   \n",
      "\n",
      "   percent_bc_gt_75  pub_rec_bankruptcies  tax_liens  tot_hi_cred_lim  \\\n",
      "0               NaN                   1.0        0.0         395328.0   \n",
      "1              60.0                   0.0        0.0          88154.0   \n",
      "2              33.3                   0.0        1.0         171118.0   \n",
      "3               0.0                   0.0        0.0         202606.0   \n",
      "4               0.0                   0.0        0.0         152081.0   \n",
      "\n",
      "   total_bal_ex_mort  total_bc_limit  total_il_high_credit_limit  \\\n",
      "0            11948.0             0.0                     17928.0   \n",
      "1            61815.0         13000.0                     52954.0   \n",
      "2            13124.0         10000.0                      7526.0   \n",
      "3            18520.0         49000.0                     20000.0   \n",
      "4            34847.0         28800.0                     38181.0   \n",
      "\n",
      "   revol_bal_joint  sec_app_fico_range_low  sec_app_fico_range_high  \\\n",
      "0              NaN                     NaN                      NaN   \n",
      "1              NaN                     NaN                      NaN   \n",
      "2              NaN                     NaN                      NaN   \n",
      "3              NaN                     NaN                      NaN   \n",
      "4              NaN                     NaN                      NaN   \n",
      "\n",
      "  sec_app_earliest_cr_line  sec_app_inq_last_6mths  sec_app_mort_acc  \\\n",
      "0                      NaN                     NaN               NaN   \n",
      "1                      NaN                     NaN               NaN   \n",
      "2                      NaN                     NaN               NaN   \n",
      "3                      NaN                     NaN               NaN   \n",
      "4                      NaN                     NaN               NaN   \n",
      "\n",
      "   sec_app_open_acc  sec_app_revol_util  sec_app_open_act_il  \\\n",
      "0               NaN                 NaN                  NaN   \n",
      "1               NaN                 NaN                  NaN   \n",
      "2               NaN                 NaN                  NaN   \n",
      "3               NaN                 NaN                  NaN   \n",
      "4               NaN                 NaN                  NaN   \n",
      "\n",
      "   sec_app_num_rev_accts  sec_app_chargeoff_within_12_mths  \\\n",
      "0                    NaN                               NaN   \n",
      "1                    NaN                               NaN   \n",
      "2                    NaN                               NaN   \n",
      "3                    NaN                               NaN   \n",
      "4                    NaN                               NaN   \n",
      "\n",
      "   sec_app_collections_12_mths_ex_med hardship_flag hardship_type  \\\n",
      "0                                 NaN             N           NaN   \n",
      "1                                 NaN             N           NaN   \n",
      "2                                 NaN             N           NaN   \n",
      "3                                 NaN             N           NaN   \n",
      "4                                 NaN             N           NaN   \n",
      "\n",
      "  hardship_reason hardship_status  deferral_term  hardship_amount  \\\n",
      "0             NaN             NaN            NaN              NaN   \n",
      "1             NaN             NaN            NaN              NaN   \n",
      "2             NaN             NaN            NaN              NaN   \n",
      "3             NaN             NaN            NaN              NaN   \n",
      "4             NaN             NaN            NaN              NaN   \n",
      "\n",
      "  hardship_start_date hardship_end_date payment_plan_start_date  \\\n",
      "0                 NaN               NaN                     NaN   \n",
      "1                 NaN               NaN                     NaN   \n",
      "2                 NaN               NaN                     NaN   \n",
      "3                 NaN               NaN                     NaN   \n",
      "4                 NaN               NaN                     NaN   \n",
      "\n",
      "   hardship_length  hardship_dpd hardship_loan_status  \\\n",
      "0              NaN           NaN                  NaN   \n",
      "1              NaN           NaN                  NaN   \n",
      "2              NaN           NaN                  NaN   \n",
      "3              NaN           NaN                  NaN   \n",
      "4              NaN           NaN                  NaN   \n",
      "\n",
      "   orig_projected_additional_accrued_interest  hardship_payoff_balance_amount  \\\n",
      "0                                         NaN                             NaN   \n",
      "1                                         NaN                             NaN   \n",
      "2                                         NaN                             NaN   \n",
      "3                                         NaN                             NaN   \n",
      "4                                         NaN                             NaN   \n",
      "\n",
      "   hardship_last_payment_amount debt_settlement_flag  term_missing  \\\n",
      "0                           NaN                    N             0   \n",
      "1                           NaN                    N             0   \n",
      "2                           NaN                    N             0   \n",
      "3                           NaN                    N             0   \n",
      "4                           NaN                    N             0   \n",
      "\n",
      "   int_rate_missing  grade_missing  sub_grade_missing  emp_title_missing  \\\n",
      "0                 0              0                  0                  0   \n",
      "1                 0              0                  0                  0   \n",
      "2                 0              0                  0                  0   \n",
      "3                 0              0                  0                  1   \n",
      "4                 0              0                  0                  0   \n",
      "\n",
      "   emp_length_missing  home_ownership_missing  verification_status_missing  \\\n",
      "0                   0                       0                            0   \n",
      "1                   0                       0                            0   \n",
      "2                   0                       0                            0   \n",
      "3                   1                       0                            0   \n",
      "4                   0                       0                            0   \n",
      "\n",
      "   issue_d_missing  loan_status_missing  pymnt_plan_missing  url_missing  \\\n",
      "0                0                    0                   0            0   \n",
      "1                0                    0                   0            0   \n",
      "2                0                    0                   0            0   \n",
      "3                0                    0                   0            0   \n",
      "4                0                    0                   0            0   \n",
      "\n",
      "   purpose_missing  title_missing  zip_code_missing  addr_state_missing  \\\n",
      "0                0              0                 0                   0   \n",
      "1                0              0                 0                   0   \n",
      "2                0              0                 0                   0   \n",
      "3                0              0                 0                   0   \n",
      "4                0              0                 0                   0   \n",
      "\n",
      "   earliest_cr_line_missing  revol_util_missing  initial_list_status_missing  \\\n",
      "0                         0                   0                            0   \n",
      "1                         0                   0                            0   \n",
      "2                         0                   0                            0   \n",
      "3                         0                   0                            0   \n",
      "4                         0                   0                            0   \n",
      "\n",
      "   last_pymnt_d_missing  next_pymnt_d_missing  last_credit_pull_d_missing  \\\n",
      "0                     0                     0                           0   \n",
      "1                     0                     0                           0   \n",
      "2                     0                     1                           0   \n",
      "3                     0                     0                           0   \n",
      "4                     0                     1                           0   \n",
      "\n",
      "   application_type_missing  verification_status_joint_missing  \\\n",
      "0                         0                                  1   \n",
      "1                         0                                  1   \n",
      "2                         0                                  1   \n",
      "3                         0                                  1   \n",
      "4                         0                                  1   \n",
      "\n",
      "   sec_app_earliest_cr_line_missing  hardship_flag_missing  \\\n",
      "0                                 1                      0   \n",
      "1                                 1                      0   \n",
      "2                                 1                      0   \n",
      "3                                 1                      0   \n",
      "4                                 1                      0   \n",
      "\n",
      "   hardship_type_missing  hardship_reason_missing  hardship_status_missing  \\\n",
      "0                      1                        1                        1   \n",
      "1                      1                        1                        1   \n",
      "2                      1                        1                        1   \n",
      "3                      1                        1                        1   \n",
      "4                      1                        1                        1   \n",
      "\n",
      "   hardship_start_date_missing  hardship_end_date_missing  \\\n",
      "0                            1                          1   \n",
      "1                            1                          1   \n",
      "2                            1                          1   \n",
      "3                            1                          1   \n",
      "4                            1                          1   \n",
      "\n",
      "   payment_plan_start_date_missing  hardship_loan_status_missing  \\\n",
      "0                                1                             1   \n",
      "1                                1                             1   \n",
      "2                                1                             1   \n",
      "3                                1                             1   \n",
      "4                                1                             1   \n",
      "\n",
      "   debt_settlement_flag_missing  \n",
      "0                             0  \n",
      "1                             0  \n",
      "2                             0  \n",
      "3                             0  \n",
      "4                             0  \n"
     ]
    }
   ],
   "source": [
    "# Create Missing Data Indicators for Categorical Columns\n",
    "def create_missing_indicators(df):\n",
    "    missing_indicators = pd.DataFrame(index=df.index)  # Create an empty DataFrame to store missing indicators\n",
    "    \n",
    "    # Loop through all columns in df\n",
    "    for col in df.columns:\n",
    "        # Check if column is categorical\n",
    "        if df[col].dtype == 'object':\n",
    "            # Create missing indicator for the categorical column\n",
    "            missing_indicators[f\"{col}_missing\"] = df[col].isna().astype(int)\n",
    "    \n",
    "    # Concatenate the original DataFrame with the missing indicators\n",
    "    df_with_indicators = pd.concat([df, missing_indicators], axis=1)\n",
    "    \n",
    "    return df_with_indicators\n",
    "\n",
    "# Run the function on the DataFrame to create missing indicators for categorical columns\n",
    "df_with_missing_indicators = create_missing_indicators(df)\n",
    "\n",
    "# Display the first few rows of the resulting DataFrame\n",
    "print(df_with_missing_indicators.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: This block preprocesses categorical variables by filling missing values with \"Other\" and applying binary encoding. Binary encoding is used here to handle high-cardinality categorical features efficiently, making the encoded features suitable for machine learning models. The target column (loan_status) is excluded from encoding to avoid unintended transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filling missing values in categorical columns: 100%|██████████| 33/33 [00:10<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape after categorical preprocessing: (100000, 308)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess Categorical Variables with Progress Bar\n",
    "categorical_columns = [col for col in df_with_missing_indicators.select_dtypes(include=['object', 'category']).columns if col != 'loan_status']\n",
    "for col in tqdm(categorical_columns, desc=\"Filling missing values in categorical columns\"):\n",
    "    df[categorical_columns] = df[categorical_columns].fillna(\"Other\")\n",
    "\n",
    "binary_encoder = ce.BinaryEncoder(cols=categorical_columns, drop_invariant=True)\n",
    "X_encoded = binary_encoder.fit_transform(df.drop(columns=['loan_status']))\n",
    "\n",
    "print(f\"DataFrame shape after categorical preprocessing: {X_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: This code fills any remaining missing values in numerical columns with zero, ensuring there are no NaN values in the dataset, which might disrupt model training. This imputation method may not be suitable for all cases but is quick for models that handle sparse data well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Imputing missing numerical values:   2%|▏         | 6/308 [00:00<00:00, 1082.31it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'term_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kiera\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'term_0'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m X_encoded \u001b[38;5;241m=\u001b[39m X_encoded\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m tqdm(X_encoded, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImputing missing numerical values\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     df[col] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame shape after numerical preprocessing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_encoded\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kiera\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\kiera\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'term_0'"
     ]
    }
   ],
   "source": [
    "# Fill Missing Numerical Values with Progress Bar\n",
    "X_encoded = X_encoded.select_dtypes(include=['number']).columns\n",
    "for col in tqdm(X_encoded, desc=\"Imputing missing numerical values\"):\n",
    "    df[col] = df[col].fillna(0)\n",
    "\n",
    "print(f\"DataFrame shape after numerical preprocessing: {X_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: This function checks the DataFrame for infinite values, which can disrupt calculations and model training. If any columns contain infinite values, it lists them; otherwise, it confirms no infinite values exist. This is a helpful quality check step before proceeding with further data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Infinite Values\n",
    "def check_infinity(df):\n",
    "    try:\n",
    "        # Apply np.isinf only to numeric columns\n",
    "        numeric_cols = df.select_dtypes(include=[np.number])\n",
    "        infinite_mask = np.isinf(numeric_cols)\n",
    "        infinite_list = infinite_mask.sum()\n",
    "        if infinite_list.sum() == 0:\n",
    "            print(\"No column has infinite values\")\n",
    "        else:\n",
    "            print(\"Columns with infinite values:\")\n",
    "            print(infinite_list[infinite_list > 0].sort_values(ascending=False))\n",
    "    except Exception as e:\n",
    "        # Identify the columns that may be causing the error\n",
    "        problematic_cols = []\n",
    "        for col in df.columns:\n",
    "            try:\n",
    "                np.isinf(df[col])\n",
    "            except TypeError:\n",
    "                problematic_cols.append(col)\n",
    "        \n",
    "        print(f\"An error occurred while checking for infinite values: {e}\")\n",
    "        if problematic_cols:\n",
    "            print(f\"The following columns may be causing the issue due to incompatible types: {problematic_cols}\")\n",
    "\n",
    "check_infinity(X_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: Here, X and y are defined as the feature matrix and target variable, respectively. The data is then split into training and testing sets, reserving 20% of the data for testing. This separation is essential for evaluating model performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that X_encoded and y are aligned\n",
    "assert len(X_encoded) == len(df), \"Mismatch between X_encoded and df, ensure they are aligned before splitting.\"\n",
    "\n",
    "# Define X and y Variables\n",
    "X = X_encoded\n",
    "y = df['loan_status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: The target variable (loan_status) is label-encoded to convert categorical values into numeric labels, which are necessary for most machine learning algorithms. This step ensures compatibility with scikit-learn’s models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Target Variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: This block calculates the Variance Inflation Factor (VIF) for each feature to assess multicollinearity. High VIF values indicate high correlation among predictors, which can affect model stability and interpretability. This information guides the removal of redundant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Missing or Infinite Values in DataFrame\n",
    "def check_missing_or_infinite(df):\n",
    "    columns_with_issues = []\n",
    "    for col in df.columns:\n",
    "        # Only process columns if they are numeric\n",
    "        if df[col].dtype in [np.float64, np.float32, np.int64, np.int32]:\n",
    "            if df[col].isna().any() or np.isinf(df[col]).any():\n",
    "                columns_with_issues.append(col)\n",
    "\n",
    "    if len(columns_with_issues) > 0:\n",
    "        print(f\"The following columns contain NaN or infinite values: {columns_with_issues}\")\n",
    "    else:\n",
    "        print(\"No columns contain NaN or infinite values.\")\n",
    "\n",
    "# Run the check on X_encoded before calculating VIF\n",
    "check_missing_or_infinite(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded[['dti', 'mths_since_last_delinq', 'mths_since_last_record', 'collections_12_mths_ex_med', 'mths_since_last_major_derog', 'annual_inc_joint', 'dti_joint', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m', 'open_act_il', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m', 'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_bc_dlq', 'mths_since_recent_inq', 'mths_since_recent_revol_delinq', 'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl', 'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m', 'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', 'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies', 'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit', 'total_il_high_credit_limit', 'revol_bal_joint', 'sec_app_fico_range_low', 'sec_app_fico_range_high', 'sec_app_inq_last_6mths', 'sec_app_mort_acc', 'sec_app_open_acc', 'sec_app_revol_util', 'sec_app_open_act_il', 'sec_app_num_rev_accts', 'sec_app_chargeoff_within_12_mths', 'sec_app_collections_12_mths_ex_med', 'deferral_term', 'hardship_amount', 'hardship_length', 'hardship_dpd', 'orig_projected_additional_accrued_interest', 'hardship_payoff_balance_amount', 'hardship_last_payment_amount']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded[['dti', 'mths_since_last_delinq', 'mths_since_last_record', 'collections_12_mths_ex_med', 'mths_since_last_major_derog', 'annual_inc_joint', 'dti_joint', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m', 'open_act_il', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m', 'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_bc_dlq', 'mths_since_recent_inq', 'mths_since_recent_revol_delinq', 'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl', 'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m', 'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', 'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies', 'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit', 'total_il_high_credit_limit', 'revol_bal_joint', 'sec_app_fico_range_low', 'sec_app_fico_range_high', 'sec_app_inq_last_6mths', 'sec_app_mort_acc', 'sec_app_open_acc', 'sec_app_revol_util', 'sec_app_open_act_il', 'sec_app_num_rev_accts', 'sec_app_chargeoff_within_12_mths', 'sec_app_collections_12_mths_ex_med', 'deferral_term', 'hardship_amount', 'hardship_length', 'hardship_dpd', 'orig_projected_additional_accrued_interest', 'hardship_payoff_balance_amount', 'hardship_last_payment_amount']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate VIF with Progress Bar\n",
    "def calculate_vif(X):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [\n",
    "        variance_inflation_factor(X.values, i) for i in tqdm(range(X.shape[1]), desc=\"Calculating VIF\")\n",
    "    ]\n",
    "    return vif_data\n",
    "\n",
    "# Calculate VIF for the original DataFrame\n",
    "vif_data_original = calculate_vif(X_encoded)\n",
    "\n",
    "# Remove features with high VIF\n",
    "high_vif_features = vif_data_original[vif_data_original[\"VIF\"] > 5][\"feature\"].tolist()\n",
    "X_encoded = X_encoded.drop(columns=high_vif_features)\n",
    "\n",
    "# Calculate VIF and print results for missing data indicators\n",
    "missing_indicators_columns = [col for col in X_encoded.columns if '_missing' in col]\n",
    "vif_data_missing = calculate_vif(X_encoded[missing_indicators_columns])\n",
    "print(\"VIF for missing data indicators:\\n\", vif_data_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: This block removes features with a VIF above 5, indicating high collinearity. By filtering out these features, we reduce redundancy, making the feature set more interpretable and less prone to multicollinearity issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove High-VIF Features\n",
    "high_vif_features = vif_data[vif_data[\"VIF\"] > 5][\"feature\"].tolist()\n",
    "X_vif_reduced = X.drop(columns=high_vif_features)\n",
    "print(\"\\nFeatures remaining after VIF filtering:\\n\", X_vif_reduced.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: Using Recursive Feature Elimination (RFE) with a linear regression model, this block selects the top 5 most informative features from the reduced feature set (X_vif_reduced). RFE iteratively removes the least important features based on the model's criteria, improving model efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination (RFE)\n",
    "model = LinearRegression()\n",
    "rfe = RFE(estimator=model, n_features_to_select=5)\n",
    "X_rfe_reduced = rfe.fit_transform(X_vif_reduced, y)\n",
    "\n",
    "selected_features = X_vif_reduced.columns[rfe.support_]\n",
    "print(\"\\nFeatures selected by RFE:\\n\", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: This final block applies RFE using a RandomForestClassifier on numerical columns. The model selects 48 features and eliminates 18 in each iteration, focusing on numerical features only. The selected features from RandomForest RFE are displayed, providing insight into the most informative numerical predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest RFE for Numerical Columns\n",
    "rf = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "rfe = RFE(estimator=rf, n_features_to_select=48, step=18, verbose=3)\n",
    "X_train_numerical = X_train.select_dtypes(include=['number'])\n",
    "rfe.fit(X_train_numerical, y_train)\n",
    "\n",
    "selected_features_rf = X_train_numerical.columns[rfe.support_]\n",
    "print(\"\\nNumerical Features selected by RandomForest RFE:\\n\", selected_features_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: Models we'll run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Define a dictionary of models to evaluate\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    \"Support Vector Machine\": SVC(probability=True, random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(silent=True, random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: This block evaluates multiple models in a dictionary called models using a progress bar to track completion. For each model, it chooses the correct evaluation function (evaluate_model_multi or evaluate_model_single) based on the multi_class_strategy parameter. If models is not defined, it provides an alert to avoid errors. The results from each evaluation are stored in a list for later review or analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating models based on user selection with progress bar\n",
    "results = []\n",
    "if models is not None:\n",
    "    for name, model in tqdm(models.items(), desc=\"Evaluating models\"):\n",
    "        # Choose the correct evaluation function based on model type\n",
    "        if multi_class_strategy:\n",
    "            result = evaluate_model_multi(\n",
    "                name, model, X_train, X_test, y_train, y_test,\n",
    "                save_path=SAVE_PATH,\n",
    "                multi_class_strategy=multi_class_strategy  # Pass strategy to evaluation function\n",
    "            )\n",
    "        else:\n",
    "            result = evaluate_model_single(\n",
    "                name, model, X_train, X_test, y_train, y_test,\n",
    "                save_path=SAVE_PATH\n",
    "            )\n",
    "            \n",
    "        results.append(result)\n",
    "else:\n",
    "    print(\"Model evaluation was not performed due to invalid selection.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: This block converts the list of evaluation results into a DataFrame for a clear summary and displays it. It optionally saves the results to a CSV file, making it easier to analyze or share the performance metrics across different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results list to a DataFrame for better visualization and analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nEvaluation Results Summary:\")\n",
    "print(results_df)\n",
    "\n",
    "# Optionally, save results to a CSV file\n",
    "results_df.to_csv(f\"{SAVE_PATH}/model_evaluation_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: This block generates a line plot to compare different performance metrics across models. Each line represents a metric, such as accuracy or F1-score, helping identify which model performs best in each area. This visualization is valuable for quickly assessing model strengths and trade-offs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `results` is the list of dictionaries created by the model evaluation function\n",
    "# Convert the list of results into a DataFrame for tabular display\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display results as a table for easy comparison\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "display(results_df)  # If running in a Jupyter notebook, this will display a nice formatted table\n",
    "\n",
    "# Visualize Performance Comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Cross-Validation Mean Accuracy']\n",
    "\n",
    "# Plot each metric for all models\n",
    "for metric in metrics:\n",
    "    plt.plot(results_df['Model'], results_df[metric], marker='o', label=metric)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Model Performance Comparison\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: This block saves each model to disk, enabling easy reuse without retraining. Each model is saved with a descriptive filename, storing it in the specified SAVE_PATH. This is especially useful when working with multiple models and allows for future analysis or deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save All Models for Future Use\n",
    "for name, model in models.items():\n",
    "    joblib.dump(model, f\"{SAVE_PATH}/{name}_final_model.pkl\")\n",
    "print(\"\\nAll models have been saved for future use.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SHAP Explanations for Model Interpretability ===\n",
    "import shap\n",
    "\n",
    "# Initialize SHAP Explainer for each model\n",
    "def explain_model_with_shap(model, X_sample, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Generates SHAP explanations for the given model and dataset sample.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    model : estimator object\n",
    "        The trained model to explain.\n",
    "    X_sample : DataFrame\n",
    "        A sample of the dataset to generate SHAP values for.\n",
    "    model_name : str\n",
    "        Name of the model for display in plots.\n",
    "    \"\"\"\n",
    "    print(f\"\\nGenerating SHAP explanations for {model_name}...\")\n",
    "    \n",
    "    # Use SHAP's TreeExplainer for tree-based models (e.g., RandomForest, XGBoost, LightGBM)\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        explainer = shap.Explainer(model, X_sample, check_additivity=False)\n",
    "    else:\n",
    "        explainer = shap.Explainer(model)\n",
    "    \n",
    "    # Calculate SHAP values\n",
    "    shap_values = explainer(X_sample)\n",
    "\n",
    "    # Plot feature importance summary\n",
    "    shap.summary_plot(shap_values, X_sample, plot_type=\"bar\", show=True)\n",
    "    \n",
    "    # Detailed summary plot with individual SHAP values per feature and instance\n",
    "    shap.summary_plot(shap_values, X_sample, show=True)\n",
    "\n",
    "    # Example force plot for the first prediction (requires a single instance)\n",
    "    shap.force_plot(explainer.expected_value, shap_values[0, :], X_sample.iloc[0, :], matplotlib=True)\n",
    "\n",
    "\n",
    "# Choose a subset of data to explain (e.g., a random sample of 100 rows)\n",
    "X_sample = X_test.sample(100, random_state=42)\n",
    "\n",
    "# Explain the main trained model (example: RandomForestClassifier)\n",
    "explain_model_with_shap(RandomForestClassifier, X_sample, model_name=\"RandomForestClassifier\")\n",
    "\n",
    "# Loop to explain all models in a dictionary (if multiple models)\n",
    "for name, model in models.items():\n",
    "    explain_model_with_shap(model, X_sample, model_name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
