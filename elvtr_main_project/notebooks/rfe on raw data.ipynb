{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE on raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data xlsx file as a dataframe\n",
    "df = pd.read_csv(\"c:\\\\Users\\\\kiera\\\\OneDrive\\\\Documents\\\\GitHub\\\\dsif-git-main-project\\\\elvtr_main_project\\\\data\\\\1-raw\\\\lending-club-2007-2020Q3\\\\Loan_status_2007-2020Q3-100ksample.csv\")\n",
    "\n",
    "# Clean headers in the existing DataFrame 'df'\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# Display cleaned headers\n",
    "print(\"Cleaned headers:\", df.columns.tolist())\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential libraries for data manipulation, statistics, and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest, shapiro, anderson, kstest, skew\n",
    "\n",
    "# Encoding and scaling libraries\n",
    "import category_encoders as ce\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt  # For standard plotting\n",
    "import seaborn as sns  # For static plots with themes\n",
    "import plotly.express as px  # For interactive plots\n",
    "import missingno as msno  # For missing data visualization\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, label_binarize\n",
    "from sklearn.model_selection import train_test_split, cross_val_score  # Data splitting and cross-validation\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, RandomForestRegressor,\n",
    "    GradientBoostingClassifier, GradientBoostingRegressor\n",
    ")\n",
    "from sklearn.svm import SVC, SVR  # Support Vector Machines for classification and regression\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB  # Naive Bayes Classifier\n",
    "from sklearn.cluster import KMeans  # K-Means clustering\n",
    "from sklearn.decomposition import PCA  # Dimensionality reduction\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.feature_selection import RFE  # Recursive Feature Elimination\n",
    "\n",
    "# Additional machine learning models\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, roc_curve, precision_recall_curve, average_precision_score\n",
    ")\n",
    "\n",
    "# Utility libraries\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "# Pandas display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Plot settings for consistent figure size (A4 landscape top half)\n",
    "FIG_WIDTH = 11.69  # Width\n",
    "FIG_HEIGHT = 4.14  # Height\n",
    "\n",
    "# Set the theme for Seaborn plots\n",
    "sns.set_theme(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_infinity(df):\n",
    "    infinite_list = df.isin([-np.inf, np.inf]).sum()\n",
    "\n",
    "    if infinite_list.sum() == 0:\n",
    "        print(\"No column has infinite values\")\n",
    "    else:\n",
    "        print(\"Columns with infinite values:\")\n",
    "        print(infinite_list[infinite_list>0]).sort_values(ascending=False)\n",
    "\n",
    "check_infinity(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_list = df.isna().sum()\n",
    "\n",
    "if nan_list.sum() == 0:\n",
    "    print(\"No column has NaN values\")\n",
    "else:\n",
    "    print(\"Columns with NaN values (sorted high to low):\")\n",
    "    print(nan_list[nan_list > 0].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Identify categorical columns in the original DataFrame\n",
    "categorical_columns = [col for col in df.select_dtypes(include=['object', 'category']).columns if col != 'loan_status']\n",
    "\n",
    "# Fill NaN in categorical columns with \"Other\"\n",
    "df[categorical_columns] = df[categorical_columns].fillna(\"Other\")\n",
    "\n",
    "# Initialize and apply BinaryEncoder to categorical columns\n",
    "binary_encoder = ce.BinaryEncoder(cols=categorical_columns, drop_invariant=True)\n",
    "X_encoded = binary_encoder.fit_transform(df.drop(columns=['loan_status']))  # Exclude target column from encoding\n",
    "\n",
    "# Fill NaN in numerical columns with 0\n",
    "numerical_columns = X_encoded.select_dtypes(include=['number']).columns\n",
    "X_encoded[numerical_columns] = X_encoded[numerical_columns].fillna(0)\n",
    "\n",
    "# Create missing data indicators for all columns with missing values\n",
    "missing_indicators = X_encoded.isna().astype(int)\n",
    "missing_indicators.columns = [f\"{col}_missing\" for col in X_encoded.columns]\n",
    "\n",
    "# Concatenate the original encoded data with missing indicators\n",
    "X_encoded = pd.concat([X_encoded, missing_indicators], axis=1)\n",
    "\n",
    "# Define X and y\n",
    "X = X_encoded\n",
    "y = df['loan_status']  # Target column\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Encode the target variable for both training and test sets\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Filter numerical columns from X_train\n",
    "numerical_columns = X_train.select_dtypes(include=['number']).columns\n",
    "X_train_numerical = X_train[numerical_columns]\n",
    "\n",
    "# Set up the RandomForestClassifier and RFE\n",
    "rf = RandomForestClassifier(n_estimators=150, random_state=42)  # Set reproducibility to 42\n",
    "rfe = RFE(estimator=rf, n_features_to_select=48, step=18, verbose=3)  # Selecting 48 features, eliminating 18 per step\n",
    "\n",
    "# Fit RFE on the filtered numerical training data\n",
    "rfe.fit(X_train_numerical, y_train)\n",
    "\n",
    "# Capture the selected numerical features\n",
    "selected_features = X_train_numerical.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've opted for a random forest classifier, but will evalute select kbest (from sklearn.feature_selection import SelectKBest, f_classif) at a later date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top features\n",
    "#selected_features = X_train.columns[rfe.support_] # I've opted to keep this for memory purpose.\n",
    "selected_features_names = list(selected_features)\n",
    "\n",
    "print(\"Selected Features by RFE:\")\n",
    "print(f\"Index: {selected_features}\")\n",
    "print(f\"Column names: {selected_features_names}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
