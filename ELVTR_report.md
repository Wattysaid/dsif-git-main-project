# ğŸ“Š ELVTR Data Science Main Project Report

## ğŸ”— Navigation Menu

- ğŸ“˜ [README](https://github.com/Wattysaid/dsif-git-main-project/blob/main/README.md)
- ğŸ“„ [Overview of DataFrame Sequence and Processing](https://github.com/Wattysaid/dsif-git-main-project/blob/main/DataFrame_Sequence_and_Processing_Overview.md)
- ğŸ“Š [ELVTR Report](https://github.com/Wattysaid/dsif-git-main-project/blob/main/ELVTR_report.md)
- ğŸ” [Feature Selection and Challenges](https://github.com/Wattysaid/dsif-git-main-project/blob/main/Feature_selection_and_challenges.md)
- ğŸ“‘ [Key Lists for Data Processing](https://github.com/Wattysaid/dsif-git-main-project/blob/main/Key_Lists_for_Data_Processing.md)
- ğŸ¤– [ML Models and Results](https://github.com/Wattysaid/dsif-git-main-project/blob/main/ML_models_and_results.md)
- ğŸ§  [Neural Network Selection](https://github.com/Wattysaid/dsif-git-main-project/blob/main/Neural_Network_selection.md)
- âš™ï¸ [Understanding Feature Impact](https://github.com/Wattysaid/dsif-git-main-project/blob/main/Understanding_feature_impact.md)
- ğŸ“ˆ [Visual Analysis](https://github.com/Wattysaid/dsif-git-main-project/blob/main/Visual_Analysis.md)

## ğŸ§  Methodology, Approach, and Model Selection Rationale

The aim of this project was to a loan application predictive model for Lending Club by analysing 100k client loan data to predict loan repayment likelyhood of loan defaults.

The approach included these key stages:

1. **Data Cleaning and Preprocessing**: ğŸ§¹ Missing values were handled, categorical variables encoded, and numerical variables normalized. Columns with low variance were removed, and outliers adjusted to enhance model performance.
2. **Exploratory Data Analysis (EDA)**: ğŸ” Analyzed feature correlations and distributions to gain insights into key factors influencing loan status. Filtered features and identified meaningful trends.
3. **Feature Engineering**: ğŸ›  New features were derived either via grouping or the combination of multiple data points, this enriched the dataset and improved the ML models predictive accuracy albeit.
4. **Model Selection**: ğŸ¯ Various models, such as Logistic Regression, Decision Trees, and Random Forest, were evaluated. Random Forest was chosen for its balance of accuracy, interpretability, and robustness.

### ğŸ” Rationale for Model Selection
Random Forest was selected due to its ability to handle complex relationships and reduce overfitting risks, as it combines the predictions of multiple decision trees.

## âœ… Advantages and âš ï¸ Limitations of the Chosen Model

### âœ… Advantages
- **High Accuracy and Robustness**: ğŸ’ª Random Forest provideded strong predictive power with a lower risk of overfitting. Yet we still have some work ahead of us to remove overfitting entirely.
- **Interpretability**: ğŸ•µï¸ Feature importance scores allow insights into key factors affecting loan decisions.
- **Versatility**: ğŸŒ It handles both numerical and categorical data well, with less sensitivity to scaling or normalization.

### âš ï¸ Limitations
- **Computational Cost**: ğŸ–¥ï¸ Training and inference was time consuming, neural networks feature reduction excercises along with SHAP tested my laptop. SHAP was executed with 1000 features only.
- **Complexity in Tuning**: ğŸ”§ Optimal performance requires intensive hyperparameter tuning.
- **Real-Time Suitability**: â³ Random Forest may not be ideal for real-time applications without optimizations.

## ğŸ—ï¸ Architecture of the Final Solution

The final solution consists of a multi-stage pipeline:

1. **Data Ingestion and Preprocessing**: ğŸ“¥ Data is loaded, cleaned, and preprocessed with feature encoding, standardization, and normalization.
2. **Feature Engineering and Selection**: ğŸ”¨ Relevant features are selected and engineered to improve predictive accuracy.
3. **Model Training**: ğŸ“ The Random Forest classifier is trained with optimized hyperparameters through cross-validation.
4. **Prediction Pipeline**: ğŸ”® For new data, the model processes inputs and outputs the probability of loan default or approval.
5. **Optional Real-Time Scoring Component**: ğŸ•°ï¸ An API framework for batch scoring, with potential for real-time scoring through API endpoints.

## ğŸš€ Deployment and Scalability Considerations

For business-as-usual (BAU) use, the following deployment and scalability considerations were made:

- **Batch Prediction Pipeline**: ğŸ“¦ Designed to handle high volumes efficiently in batch mode.
- **Cloud Hosting and Integration**: â˜ï¸ Deployment options (e.g., AWS or GCP) to leverage scalable cloud resources.
- **Real-Time Extension**: â±ï¸ API deployment for real-time scoring, optimized to reduce latency if needed.
- **Model Monitoring and Retraining**: ğŸ”„ Regular monitoring and retraining scheduled to maintain accuracy as data distributions change.

## ğŸ“ˆ Estimated Impact and ROI

The deployment of this model is expected to bring significant benefits:

- **Reduce Loan Default Rates**: ğŸ”’ Accurately identifies high-risk loan applications, reducing defaults and improving portfolio health.
- **Increase Operational Efficiency**: ğŸƒ Streamlines the decision-making process, reducing time and resources spent on manual evaluations.
- **Enhance Customer Experience**: ğŸ˜Š Faster approvals for low-risk customers improve satisfaction and retention.
- **Expected ROI**: ğŸ’¸ Improved loan performance is anticipated to lead to cost savings and reduced manual intervention. The exact ROI depends on improvements in Lending Clubâ€™s default rates and operational savings.

